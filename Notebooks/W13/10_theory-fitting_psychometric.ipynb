{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal here is to compare methods which fit data with psychometric curves using logistic regression. Indeed, after (long) experiments where for instance you collected sequences of keypresses, it is important to infer at best the parameters of the underlying processes: was the observer biased, or more precise? \n",
    "\n",
    "While I was *forevever* using [sklearn](https://scikit-learn.org/stable/index.html) or [lmfit](https://lmfit.github.io/lmfit-py/) (that is, scipy's [minimize](https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.minimize.html)) and praised these beautifully crafted methods, I sometimes lacked some flexibility in the definition of the model. This notebook was done in collaboration with [Jenna Fradin](https://github.com/jennafradin), master student in the lab.\n",
    "\n",
    "> tl; dr = Do not trust the coefficients extracted by a fit without validating for *methodological* biases.\n",
    "\n",
    "One part of flexibility I missed is taking care of the *lapse rate*, that is the frequency with which you just *miss the key*. In a psychology experiment, you often see a fast sequence of trials for which you have to make a perceptual deccision, for instance press the Left or Right arrows. Sometimes you know the answer you should have done, but press the wrong eror. This error of distraction is always low (in the order of 5% to 10%) but could potentially change the results of the experiments. This is one of the aspects we will evaluate here.\n",
    "\n",
    "In this notebook, I define a fitting method using [pytorch](https://pytorch.org/) which fits in a few lines of code :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "torch.set_default_tensor_type(\"torch.DoubleTensor\")\n",
    "criterion = torch.nn.BCELoss(reduction=\"sum\")\n",
    "\n",
    "class LogisticRegressionModel(torch.nn.Module):\n",
    "    def __init__(self, bias=True, logit0=-2, theta0=0, log_wt=torch.log(0.1*torch.ones(1))):\n",
    "        super(LogisticRegressionModel, self).__init__()\n",
    "        #self.linear = torch.nn.Linear(1, 1, bias=bias)\n",
    "        self.theta0 = torch.nn.Parameter(theta0 * torch.ones(1))\n",
    "        self.logit0 = torch.nn.Parameter(logit0 * torch.ones(1))\n",
    "        self.log_wt = torch.nn.Parameter(log_wt * torch.ones(1))\n",
    "\n",
    "    def forward(self, theta):\n",
    "        p0 = torch.sigmoid(self.logit0)\n",
    "        #out = p0 / 2 + (1 - p0) * torch.sigmoid(self.linear(theta))\n",
    "        out = p0 / 2 + (1 - p0) * torch.sigmoid((theta-self.theta0 )/torch.exp(self.log_wt))\n",
    "        return out\n",
    "\n",
    "learning_rate = 0.005\n",
    "beta1, beta2 = 0.9, 0.999\n",
    "betas = (beta1, beta2)\n",
    "num_epochs = 2 ** 9 + 1\n",
    "batch_size = 256\n",
    "\n",
    "def fit_data(\n",
    "    theta,\n",
    "    y,\n",
    "    learning_rate=learning_rate,\n",
    "    batch_size=batch_size,  # gamma=gamma,\n",
    "    num_epochs=num_epochs,\n",
    "    betas=betas,\n",
    "    verbose=False, **kwargs\n",
    "):\n",
    "\n",
    "    Theta, labels = torch.Tensor(theta[:, None]), torch.Tensor(y[:, None])\n",
    "    loader = DataLoader(\n",
    "        TensorDataset(Theta, labels), batch_size=batch_size, shuffle=True\n",
    "    )\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    logistic_model = LogisticRegressionModel()\n",
    "    logistic_model = logistic_model.to(device)\n",
    "    logistic_model.train()\n",
    "    optimizer = torch.optim.Adam(\n",
    "        logistic_model.parameters(), lr=learning_rate, betas=betas, amsgrad=False\n",
    "    )\n",
    "    for epoch in range(int(num_epochs)):\n",
    "        logistic_model.train()\n",
    "        losses = []\n",
    "        for Theta_, labels_ in loader:\n",
    "            Theta_, labels_ = Theta_.to(device), labels_.to(device)\n",
    "            outputs = logistic_model(Theta_)\n",
    "            loss = criterion(outputs, labels_)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            losses.append(loss.item())\n",
    "\n",
    "        if verbose and (epoch % (num_epochs // 32) == 0):\n",
    "            print(f\"Iteration: {epoch} - Loss: {np.sum(losses)/len(theta):.5f}\")\n",
    "\n",
    "    logistic_model.eval()\n",
    "    Theta, labels = torch.Tensor(theta[:, None]), torch.Tensor(y[:, None])\n",
    "    outputs = logistic_model(Theta)\n",
    "    loss = criterion(outputs, labels).item() / len(theta)\n",
    "    return logistic_model, loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and run a series of tests to compare both methods.\n",
    "\n",
    "<!-- TEASER_END -->\n",
    "\n",
    "Let's first initialize the notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pylab import rcParams\n",
    "# print(rcParams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fontsize = 20\n",
    "rcParams[\"font.size\"] = fontsize\n",
    "rcParams[\"legend.fontsize\"] = fontsize\n",
    "rcParams[\"axes.labelsize\"] = fontsize\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some hyper parameters which we will tune later:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 256\n",
    "# batch_size = N//4\n",
    "# batch_size = N//2\n",
    "\n",
    "N_cv = 8\n",
    "\n",
    "seed = 1973\n",
    "N_scan = 9\n",
    "N_test = N * 8 # number of points for validation\n",
    "\n",
    "bias = True\n",
    "\n",
    "p0 = 0.1\n",
    "theta0 = 0.0\n",
    "wt = np.pi / 24\n",
    "theta_std = np.pi / 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## problem statement: a 2aFC task on synthetic data\n",
    "\n",
    "We will generate a typical setup where we have to guess for the otientation of a visual display compared to the vertical and ask observer to either press on the `left` or `right` arrows. The visual display will be controlled by a $theta$ parameter which we draw randomly according to a Gaussian probability density function. This may be synthesized in the following *psychometric* function:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def psychometric_function(theta, p0=p0, theta0=theta0, wt=wt):\n",
    "    return p0 / 2 + (1 - p0) / (1 + np.exp(-(theta - theta0) / wt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "such that we can draw the data according to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(N=N, p0=p0, theta0=theta0, wt=wt, theta_std=theta_std, seed=seed, **kwargs):\n",
    "    np.random.seed(seed)\n",
    "    # theta = np.random.randn(N)*theta_std\n",
    "    theta = (2 * np.random.rand(N) - 1) * theta_std\n",
    "\n",
    "    p = psychometric_function(theta, p0, theta0, wt)\n",
    "\n",
    "    y = np.random.rand(N) < p  # generate data\n",
    "    return theta, p, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35.7 µs ± 4.26 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "theta, p, y = get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0 - Loss: 0.37768\n",
      "Iteration: 16 - Loss: 0.37494\n",
      "Iteration: 32 - Loss: 0.37302\n",
      "Iteration: 48 - Loss: 0.37187\n",
      "Iteration: 64 - Loss: 0.37130\n",
      "Iteration: 80 - Loss: 0.37107\n",
      "Iteration: 96 - Loss: 0.37099\n",
      "Iteration: 112 - Loss: 0.37097\n",
      "Iteration: 128 - Loss: 0.37095\n",
      "Iteration: 144 - Loss: 0.37095\n",
      "Iteration: 160 - Loss: 0.37094\n",
      "Iteration: 176 - Loss: 0.37094\n",
      "Iteration: 192 - Loss: 0.37093\n",
      "Iteration: 208 - Loss: 0.37093\n",
      "Iteration: 224 - Loss: 0.37093\n",
      "Iteration: 240 - Loss: 0.37093\n",
      "Iteration: 256 - Loss: 0.37092\n",
      "Iteration: 272 - Loss: 0.37092\n",
      "Iteration: 288 - Loss: 0.37092\n",
      "Iteration: 304 - Loss: 0.37092\n",
      "Iteration: 320 - Loss: 0.37092\n",
      "Iteration: 336 - Loss: 0.37092\n",
      "Iteration: 352 - Loss: 0.37092\n",
      "Iteration: 368 - Loss: 0.37092\n",
      "Iteration: 384 - Loss: 0.37092\n",
      "Iteration: 400 - Loss: 0.37092\n",
      "Iteration: 416 - Loss: 0.37092\n",
      "Iteration: 432 - Loss: 0.37092\n",
      "Iteration: 448 - Loss: 0.37092\n",
      "Iteration: 464 - Loss: 0.37092\n",
      "Iteration: 480 - Loss: 0.37092\n",
      "Iteration: 496 - Loss: 0.37092\n",
      "Iteration: 512 - Loss: 0.37092\n",
      "Final loss = 0.37092229797854126\n"
     ]
    }
   ],
   "source": [
    "theta, p, y = get_data()\n",
    "logistic_model, loss = fit_data(theta, y, verbose=True)\n",
    "print(\"Final loss =\", loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That method is fairly quick, in approx 2 seconds on my MacBook Pro (Early 2015) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.03 s ± 281 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "logistic_model, loss = fit_data(theta, y, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compare now the retrieved values. Remember the true values used to generate the data are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p0 = 0.100, theta0 = 0.000, wt = 0.131, theta_std = 1.571\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    f\"p0 = {p0:.3f}, theta0 = {theta0:.3f}, wt = {wt:.3f}, theta_std = {theta_std:.3f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is what we get out of our method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "theta0 = 0.001\n",
      "slope = 0.129\n",
      "p0 = 0.168\n"
     ]
    }
   ],
   "source": [
    "def get_params(logistic_model, verbose=False):\n",
    "    theta0_ = logistic_model.theta0.item() # -logistic_model.linear.bias.item() / logistic_model.linear.weight.item()\n",
    "    wt_ = torch.exp(logistic_model.log_wt).item() # 1 / logistic_model.linear.weight.item()\n",
    "    p0_ = torch.sigmoid(logistic_model.logit0).item()\n",
    "\n",
    "    if verbose:\n",
    "        if bias:\n",
    "            print(f\"theta0 = {theta0_:.3f}\")\n",
    "        print(f\"slope = {wt_:.3f}\")\n",
    "        print(f\"p0 = {p0_:.3f}\")\n",
    "    return theta0_, wt_, p0_\n",
    "\n",
    "\n",
    "theta0_, wt_, p0_ = get_params(logistic_model, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's do the same thing with `sklearn`: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "tol = 1.0e-5\n",
    "C = 3.0\n",
    "\n",
    "def fit_data_sklearn(theta, y, num_epochs=num_epochs, tol=tol, C=C, verbose=False, **kwargs):\n",
    "    logistic_model = LogisticRegression(\n",
    "        solver=\"liblinear\", max_iter=num_epochs, C=C, tol=tol, fit_intercept=True\n",
    "    )\n",
    "    logistic_model.fit(theta[:, None], y)\n",
    "\n",
    "    outputs = logistic_model.predict_proba(theta[:, None])[:, 1]\n",
    "    outputs_, labels = torch.Tensor(outputs[:, None]), torch.Tensor(y[:, None])\n",
    "    loss = criterion(outputs_, labels).item() / len(theta)\n",
    "    if verbose:\n",
    "        print(\"Loss =\", loss)\n",
    "    return logistic_model, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss = 0.39479121529142247\n"
     ]
    }
   ],
   "source": [
    "logistic_model_sk, loss = fit_data_sklearn(theta, y, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is what we get out of this classic method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "theta0 = 0.018\n",
      "slope = 0.392\n"
     ]
    }
   ],
   "source": [
    "def get_params_sk(logistic_model, verbose=False):\n",
    "\n",
    "    theta0_ = -logistic_model.intercept_[0] / logistic_model.coef_[0][0]\n",
    "    wt_ = 1 / logistic_model.coef_[0][0]\n",
    "\n",
    "    if verbose:\n",
    "        if bias:\n",
    "            print(f\"theta0 = {theta0_:.3f}\")\n",
    "        print(f\"slope = {wt_:.3f}\")\n",
    "    return theta0_, wt_\n",
    "\n",
    "theta0_, wt_ = get_params_sk(logistic_model_sk, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That method is *much* quicker:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "674 µs ± 25.9 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "logistic_model_sk, loss = fit_data_sklearn(theta, y, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... but what is the value of few seconds after hours of having observers sitting in front of a screen looking at (often boring) visual displays? More seriously, most important is the reliability of the values which are inferred by each respective method, such that they are correctly reflecting the information contained in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## qualitative comparison of methods\n",
    "\n",
    "We can synthesize this comparison by drawing a new dataset and plotting the psychometric curves which are obtained by each method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss = 0.371\n",
      "Training sklearn loss = 0.395\n"
     ]
    }
   ],
   "source": [
    "theta, p, y = get_data()  # nouvelles données\n",
    "logistic_model, loss = fit_data(theta, y, verbose=False)\n",
    "print(f\"Training loss = {loss:.3f}\")\n",
    "logistic_model_sk, loss_sk = fit_data_sklearn(theta, y, verbose=False)\n",
    "print(f\"Training sklearn loss = {loss_sk:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA5IAAAH1CAYAAACEH8HZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAIABJREFUeJzs3Xd8leX9//HXnZzsSQiEEELCCBvFCiJDWVaxVnFVHFVx1LZq1ba/tl+/1oqto1a/Vhx8RVvEVhz9anHViQtikL1DIATCDDNkz5Pcvz8uzslJcrIgycl4Px+P+3HOfd3rc48c+Xhd93VZtm0jIiIiIiIi0lx+vg5AREREREREOhclkiIiIiIiItIiSiRFRERERESkRZRIioiIiIiISIsokRQREREREZEWUSIpIiIiIiIiLaJEUkRERERERFpEiaSIiIiIiIi0iBJJERERERERaRGHrwPoSGJjY+3k5GRfhyEiIiIiIuITa9euPWbbdq+m1lMi6SE5OZk1a9b4OgwRERERERGfsCxrT3PWU9NWERERERERaRElkiIiIiIiItIiSiRFRERERESkRZRIioiIiIiISIsokRQREREREZEWUSIpIiIiIiIiLaJEUkRERERERFpEiaSIiIiIiIi0iBJJERERERERaRElkiIiIiIiItIiSiRFRERERESkRZRIioiIiIiISIu0WSJpWdZUy7Jsy7LmtsK+bMuyvj79qEREREREROR0NSuRPJnIeU5VlmXlWpb1tWVZcyzLsto60JZozSRWREREREREanO0cP2HT34GAIOBK4ApwFjg7jrrrgKGA8dOJ0ARERERERHpWFqUSNq2Pddz3rKsScAy4E7Lsv7Htu3dHuuWABmtEaSIiIiIiIh0HKf1jqRt299ikkULONtzWWPNSy3LGmdZ1meWZRVallVgWdZSy7ImWJY19+Q2U70dz7KsWMuyXrIsK8eyrHLLsrZalnVLnXUWAV+dnH2oTpNcr/sVERERERGR5muNznZc70dWNmtlyzoPU4s5HfgIeB4oxSR/5zSyaTTwLTABeBv4B9AXWGhZ1s0e670LvHry+zeY5riuKbs5MXZVTqeTY8eO4XQ6u9SxpHNoi2eisz9nvoq/Jcf1XPdUt2tPzTmua52ysrJmr9uS83A6nRw6dIhDhw41uV1T+/cWa0PbNHSv6n73Fpu3fbbkPBpSVlbG9u3bKSoqanBfruPs37/fvbzuedf9dDqd7n2XlZU161o2dF1dcXl7Huru0/OYjR3PW2z79+9n69at7m3rHvdUzq2pe9TU329j59fQ/lvym+Dt3jYUX0PXr+46zXnOTyXO1thPU/tubB3P63wqvwsNqXtPve3L9WwWFRV5/b3xvIeefzOe16i5vyvezsHbuTd0HM+4PP+mWnq9697T5l7LrVu3kp2d3Sb3qjNq6TuStViWdT4wFKjAvBPZ1Pp+wEIgGPiBbdsfeyz7GfC/jWx+JvB34Ke2bVed3OavwCbgd5xMHm3bfteyrDzgZuDrus1xuyun08miRYvIyspi0KBBzJkzB4fjtG5/hziWdA5t8Ux09ufMV/G35Lie6yYnJwOQnZ3dou062rm51snMzCQnJ4f4+HhSUlIaXbcl5+F0Ovn73//Ou+++C8Dll1/Obbfd5nW7pvbvLdaBAwcC9e9DQ/eq7veqqio++OCDWrEB9eIAmn0eDSkrK+OOO+5gx44dAERGRuLv719rX67rtWTJEvbv309CQgKzZs3C39+fXbt2kZOTQ1xcHIcPH3Z/xsfHk5SURFpaGllZWaSkpDB//nzefPPNFj3XmZmZHDhwgGPHTFcOsbGxJCQkuJ+Hutfl2muv5c477yQzM5NBgwYxceJE9u3bV+94rvPOzMx0x/aPf/yD+fPnU1JSwrnnnsuECRP46KOPqK6uplevXsTHx7f43Jp61pr6+23s/FzHXbx4ca3933zzzbz22mvN+k3wdm+vvPLKWvfe2/Pvef3qXucf//jHXo9fN5aG1mvs78zbui3ZT2PPWlO/SZ738dJLL8Xf37/JeJvzG1b3WXzppZcIDg6uta+XXnqJ+fPnU1xcTFxcHJMmTeLo0aPu35uqqiref/999z3s2bMnubm5WJblfiZeffXVes9h3efLMz5vf4OWZbnPfdeuXbXKvT17FRUVLFiwgJKSEiZOnMjf/vY3HA5Hs/8b4HlPXb81TV3L22+/nbS0NMrKyhg1ahSXX355q92rzqpFNZInm57OtSzrUcuy3gKWYmok/59t2znN2MVETCc9X3kmkSe9BOxoZNsS4FeuJBLAtu10TC3lcMuyIlpyLi6WZd1hWdYay7LWHD169FR20Snk5eWRlZXFgAEDyMrKIi8vr0scSzqHtngmOvtz5qv4W3Jcz3XT09NJT09v8XYd7dxc68TFxZGZmUlcXFyT67bkPPLy8khPT3fPp6enN7hdU/v3FmtD96Ghe1X3+4YNG+rF5i2OlpxHQ/bs2UNmZiaJiYlkZ2dTWlpab1+u41RWVlJSUoLT6WTDhg2kp6e7zzsiIqLWZ1xcHBs2bCAjI4NBgwaRmZnJli1bWvxcx8XFkZGRQWVlJZWVlWRkZNR6Hupely1btriTm4yMDDZs2OD1eK7z9oxtw4YNlJSUEBoaSnp6OqtXrwbMPzQzMjJO6dyaukdN/f02dn6u49bd/549e5r9m+Dt3ta9997Oy/P61b3ODR2/biwtjbOhdVuyn8aetaZ+kzyvs+v5b8nvQkP7rvss7tmzp96+XM9mUFAQ2dnZOByOWr83GzZscN/DkpIS9z31fCa8PYeNnbu3v0HPc69b7u3ZW716tftvKiMjgz179rTovwGe97S51zIjI4PAwEBKSkooLS1t1XvVWbU0HX6ozrwN3Gbb9ivN3P6sk5+pdRfYtl1tWVYaMKSBbTNt2y7wUr7v5Gc0UNjMODyP+xImiWXs2LF2S7fvLKKjoxk0aJD7/9JER0d3iWNJ59AWz0Rnf858FX9Ljuu57ogRIwDYvXt3i7braOfmWsf1f+gPHz5MSkpKo+u25Dyio6MZMWKEuxZuxIgRDW7X1P69xdrQfWjoXtX9XlVVxb59++rF5i2O5p5HQ5KSkkhJSWHHjh0kJycTEhJSb1+u67V9+3ZCQ0NxOByMGTPGXSuRkpJCYWFhrc/Dhw8zZswYSkpK3LV2o0aNcidczX0+MzMzGTZsmLtGctiwYfWeB8/rMmrUKFJSUtzbjRkzxuvfg+u8Xfdt1KhRjBkzhrS0NHeN5Lhx4/joo49wOBwMGzbslM6tqWetOX+/DZ2f67h195+UlNTs3wRv97buvff23Hlev7rXuaHj142lpXE2tG5L9tPYs9bUb5LndXY9/03F25zfsLrPYlJSUr19uZ7N4uJikpOTcTqdtX5vqqqq2Lt3L6GhoYSGhpKYmEhubi5Q80w09Bw2dO4N/Q16/u17lnt79ioqKli3bh0lJSWMGTOGpKQkHA5Hs/8b4HlPXb81TV3LYcOGkZaWRmhoKCEhIa16rzory7abzp0sy7IBbNu2Ts6HYd5V/DvQB7jYtu0v62wzFfPe48Ou5qWWZf0e+BNwt23bL3g5zp8xzVSn2bb9dZ3jf2Pb9lQv2yzCNGMdYNt2dkPHbo6xY8faa9asae7qnY7T6SQvL4/o6Og2r1Jvz2NJ59AWz0Rnf858FX9Ljuu5LnBK23W0c3OtEx4eTlFRUbPWbcl5uN6JAdNcsrHtmtq/t1jB+31o6F7V/e4tNm9xtOQ8GlJWVsaePXtISEigqKjI67483zFyOBzExsa6Y3add93P6OhonE4ne/bsISkpieDg4FN6rsPDw921A9HR0fWeh7r7dJ2P6x+tDR3Pcz1XbIcOHSI/P59BgwbhcDjc19Z13FM5t6buUVN/v42dn+u4dfffkt8Eb/e2oWfWs7yx69yc5/xU4myN/XjT3N8kz+vc3Hib8xtW955625fr2UxKSqKsrKze743nPYyOjnb/zXg+E839XfF2Dp77c5173XJv98Lzb8p1bi35b4DnPW3utczKyiIsLIzg4OBWv1cdiWVZa23bHtvkeqeSSHqUnwGsA3KAoSeH/HAtm0r9RPIeYB7wJ9u2/+DlOK8Ac1AiKSIiIiIi0u6am0ie7vAfm4CXgX7AL5uxyfqTn5PrLjjZEc/E04nHg+s9Sv9W2p+IiIiIiIic1BrDfzwClAH/z7KsHk2s+y2QBUyzLOviOsvuoOH3I1vq+MnP/q20PxERERERkVNTUQHHj8Pu3bBhAyxbBh9+CAcP+jqyU3bajXRt2z5gWdYC4F7gt8D9jaxbbVnW7cAnwPuWZb2DSSzPAL4PfAxcDFSfZljbgQPAtZZlVQB7MR0D/dO27T2NbikiIiIiItIYpxPy8syUn18zuebz8qCgwHwvKIAGxvLkV7+Cvn3bN/ZW0lpvez4O/AS4x7KsZ2zbPtzQirZtf21Z1hRMTeYlJ4tXAtOAG07Oe+udtdls266yLOsK4M/ANUAEZpiSVECJpIiIiIiI1GbbUFRkag5PnIDcXPOZl1f788QJs15rKDittMenmpVI1u1kx8vyw0BYnbKvMcmbt/VXYmoga7Es6ynM+42ZzT2+bdtzMB301C1fDcxoLG4REREREekGystNgnj8OBw7VvM9N7d24uh0ts3x/f0hMrL2FBUFdYZl6Uzavf9Zy7JCgUDbtvPqlM/BdLbzsW3bxe0dl4iIiIiIdEJOp0kGjx6tmY4dq/k8dqz1ahBdLAuio80UFWUmz++eU2QkhIaabboQXwxk0h9Yb1nW58DOkzGchenJNQ/4tQ9iEhERERGRjqiy0iSFR47A4cP1P0+cMM1SW0NoKMTEmKlHj5rP6OjanxER4Nca/ZZ2Xr5IJA8Di4EpmPcig4BDwCvAo7ZtZ/kgJhERERER8QXbhsJCyMmBQ4fMlJNjksScHNPk9HQTRX9/6Nmz9hQbaxLFnj1rEsbg4NY5p26g3RNJ27ZPALe393FFRERERMSHCgvNcBcHDphP1/ecHCgtPfX9WpZJAnv1qj3FxpqpVy/TxLSLNS31NV/USIqIiIiISFfkdJoaxf37a08HDpz6e4qWZRLCuDjo3dtMnt9jY8GhtKa96YqLiIiIiEjLVFSYBHHvXtizx3zft88kkVVVLd9fcDD06QPx8ebT83uvXkoUOyDdERERERER8a6qyjRBzc6uSRr37jVlLX1vMSgI+vb1PqnpaaejRFJERERERMw7jLt310yu5LGysmX76dUL+vWrPSUkmA5tlCx2GUokRURERES6E9s24y5mZcHOneYzK8v0jtpclmWanfbvD0lJkJhopoQE9XzaTSiRFBERERHB5FeeU1NljX1vaN7zs6myut9PZTm2jXX8GP67MnFk78SxJwv/PVn4FeTX3qb+btyqe8TiTEymKiGJqn5JOPv2pyq+n2mqWtexlrd4ba0hIDub0FDTT1BnpURSRERERFqNbZuOOysrzWdVlZlc3z0/q6trlnv7Xl1df3KV23btT29lnp+uqe583SSxs3OUFRF1JJOowzuIOrKD6MM7CCzJa9a21Y5AimL6UxA7gMKeAyiMTaaoZzKVwRE1K+WdnNLbJPxuZdAgmDHD11GcOiWSIiIiIkJVFZSX158qKkxS2NCnZ9LoShJPh5+fmfz9a757Tq5yy6qZdzhqlltWzTLPeVeZ57xnuevY4H0d16t9zfne0Lznp7cyb8s81VteXY3/gb0E7NxGwM5tOLK243f4oFnuWjHi5FSHHRJCVdIgnEmDqEo2n3bfBEL8/elVf/UGY2pIe74K2Vlfu/RWoduZKJEUERER6YKqq80Y78XF5rO0FMrKar57lpWXN50A+vtDQAAEBtZ8hoaaJC4gwHzW/e6a/P1rEj5v3+smiNKA4mLYvh22bYOMDPO9tLT2Ot5eTwwJgZQUGDzYTIMGmaE1dLHlNCiRFBEREemEysuhoMBMxcVmrPfi4pqppMR7c82AAJNXhIRAZKTpYDMoyPSPEhhY/9M1uWrrpB3l58PWrbBli5mys5tug+twwIABJnEcMsRM/fopaZRWp0RSREREpIOqrDQdaebn1ySNru/l5bXXDQiAsDAID4cePcx31+RKHIODNa57h3bsmEkYXcnj/v1NbxMTA8OHm2nYMJNEBga2fazS7emnRERERMTHqqtNgpibW3sqLKxZx7JMkhgVZVomRkbWTOHhyh06pYIC2LwZNm4008GDja9vWTBwYO3EsVcv1TaKTyiRFBEREWlnRUVw+HDNdPy4SSbB5ATR0dC7t8kTevQwU0SEmpd2emVlprbRlTju3t14U1WHwzRNHTUKRo40yWNISPvFK9IIJZIiIiIibai6Go4ehUOH4MgRkziWlJhlDoepUBo92rRQjIkxSaS/v29jllZi2+a9xnXrzJSebrq2bUhgoPm/B6NHm8Rx6FBVNUuHpURSREREpJUVFcG+fWY6eNAMlQGmGWrfvhAXZ6aYGNUydjmFhbB+vUkc1683bZQb4udnahzPPNNMShylE1EiKSIiInKanE7IyTGJ4/79kHdy/PfwcPNKW79+ZrQFtUrsgmwb9u6FVavMtH17481Vk5NrEsdRo/RQSKelRFJERETkFFRXw4EDsHOnedXN6TRNUuPjzatsiYmmmap0QZWVppOc1atN8njkSMPrRkTAmDFw9tlw1lmmGlqkC1AiKSIiItJMtm3ecdy5E3btMn2nBAaaMd4HDDBJpIbX6KKKi03iuGKFabZaVuZ9PcsyTVRdiWNKitovS5eknzoRERGRJuTnmxaLO3ea9x8dDkhKMglkv37qHOd02LZNlV2Fs9pJZVVlve9V1VXuT2e1s15ZtV1NlW0+q+1qd1ndctu2a5Xbto2NXW+Zje2eDygsJnZTFr037aRH5n78qqpOtlo1TVddDVidQQEcGdqPwyOTODQ0gYqwYGw7Bzv3IKzEfSzbdm3X8HfXNfGcd5V5znuWu783srzuvuqtV2dbb+s0xtuxT3VfrXXc0953G8btcsXwKzi337ltfpy2oERSREREpAEHD8KmTeYVOMsySeO4ceY1t4AAX0fXtpzVTkoqSyhzlrk/y5xllFaWmk+n+Sx3llNRVUF5VTnlznLKq07OnyyvrK6ksqqy5vvJ+crqSpzVTpzVjfRi6gORBeUM33GCYZknSDxQhGXbOIGjddbLjQ4mc3A0OwZGs7dfONX+NpANR7LbPWbpvKaWTvV1CKdMiaSIiIiIh6oqU/O4ebPpcDM42LRSHD4cQkN9HV3L2LZNmbOMwopC8svyKSgvoLCikILyAvdUVFFESWWJ+7O4spjiimLKq8p9HX67CS+qYPj2E4zcfpzEA0UNrnewTxgZKT3YntKDYzHB5v8uiHRTSiRFREREgNJSM8xferr5HhMDU6aY5qsdselqRVUFR4uPcqT4CLmlueSW5nKi7ETN99IT5JblUlFV4etQm+Rv+ePwc7inAP8Ad5mf5ecud333t/zxs/zw9/Ov9d3P8nPPNzUFFZcTtymLuHXbid55FMsGrGisSNNDkoUFfhYFg/qTd9Ywcs8cgn9sDCOB0ZYflmVhYWGdTCYtLPws8y6ka1lD3z238fbdffw627vm667jyXN/DS2ru9xqICGuu4+G1msOb/G01r7bUlNxn674iPg23X9bUiIpIiIi3Vp5uRnub+tWUxvZv78ZDz4hwbdx2bbN8dLj7C/YT05hDkeKj3Ck+AiHiw9zpPgIJ8pOtOnxLSzCAsMIcYQQ7AgmxBFCSEDN92BHMMGOYIIcQQT5BxHoH+j+HuQw84H+gQT4BZhP/wAC/AII8A9wl7sSxnZLIsrKTGc533xjbnp1tSmP8LjZfn6ml9VJk2D8eOKjotonNpFORomkiIiIdEtVVSZ5XL/eJJNDhphONts7b3BWO8kpzGFfwT72F+xnX7753F+4nzJnAz2DtkCgfyCRQZFEBkaaT48pIiiCiMAIwgLDCAsIIzQg1P092BHcYWuJWqS62rzo+uWXJon01tuqZZn/e3DeeTBxIkRGtn+cIp2MEkkRERHpVmwbsrLM8H9FRWa8x/Hj22d4P2e1k335+9iZu9M97c7bTWV1ZYv35Wf5ERsSS++w3vQM7UlMSAw9gnuYz5Ae7vnQgNCukRC21J498NVXZsrN9b7O8OEmeZw0SeM7irSQEkkRERHpNg4ehO++g2PHIDbWvAPZlk1YT5SeYPORzWw9svWUksbwwHASIxPpG9GXuLA4eof1Ji7cfPYM6Ym/Xwd8edOXiopMs9XPPzf/t8CbxESYPh3OPx96927f+ES6ECWSIiIi0uWVlMDy5aaSKjwcpk0znei0dkVdflk+m49sZvPhzWw6vIn9hfubtV1saCz9I/uTGJVIv8h+9IvsR2JkIpFBkd2zNrElbBu2bIHPPoO0NKjw0rlQVJT5vwbTpsGgQeptVaQVKJEUERGRLm3nTvj2W/NO5PjxMGpU6/XCWlVdRfrRdL7b/x0bD29kT/6eJrfpFdqLlJgUBsUMYnDMYAbHDCYySO/ktVhurnnv8bPPICen/vKAAHPDp083L7869M9ekdakvygRERHpkkpLITUVdu+GuDiYOrV1OtKpqKpg46GNrNi/gu/2f0dhRWGD6zr8HAzrOYzRcaMZFjtMSePpsm3YuBH+8x/zkqur11VPgwbBhReaGsiwsPaPUaSbUCIpIiIiXc7u3aYpa0WFqZQ644zTa81YWlnKmoNrWLF/BasPrm6wN1WHn4OUmBTOiDuDM+LOYFjsMAL9A0/9wGIUFcEXX8BHH5kXXesKCzOJ44UXmkRSRNqcEkkRERHpMsrLTTPWnTtNZzrTpkGPHqe+v8zjmXyy8xOW7V3WYPIYExLDhH4TOCfhHEb0GkGwI/jUDyi1ZWWZ2sdvvvH+7uOoUSZ5nDgRgoLaPz6RbkyJpIiIiHQJBw+aV+bKyuDss81rcX5+Ld9PaWUp3+z5hk92fkLWCe89f8aHxzMxcSIT+k1gSM8h6hCnNTmdpk3yhx/C9u31l4eFwYwZ8IMftG2XuyLSKCWSIiIi0ult3Wo67IyKgpkzTW1kS2XlZvHJzk/4es/XXmsfEyMTOa//eUxInEBSVJKSx9ZWWAiffGISSG/jPg4cCJdcYobtCFatr4ivKZEUERGRTqu62iSQ6enQv7+pqAoIaNk+Nh/ezOubX2fL0S31lgX4BTC5/2RmDp7J8NjhSh7bwoED8N575h3Ius1XHQ447zxT+zh0qIbtEOlAlEiKiIhIp1ReDkuXmjzkzDPhnHNalmc0lkD2i+jHzMEzmT5gOhFBEa0YtQCm99VNm+Ddd2HNmvrLe/QwtY8zZ7ZOV7si0uqUSIqIiEink59vWkEWFprOOocObf62W45s4fXNr7P5yOZa5f6WP5P7T+biwRczotcI1T62BVcV8v/9H+zaVX/5wIEwa5aphWxp1bKItCslkiIiItKpHDgAn39uOtL54Q+hT5/mbddYAjljwAyuGXkNceFxbRCxUFlpekJ65x3Iyam9zLJg3Di4/HLTC6sSeJFOQYmkiIiIdBrp6WZ4j+ho0+oxohmtTnNLc3lp7Ut8u+/bWuVKINtBaampOn733fod6AQGwgUXmBrIvn19E5+InDIlkiIiItIprFtnXqfr3x+mTzd5SGOq7Wo+yvyIf2z8B6XOUne5n+XnTiD7hDezOlNaprDQdKDz4YdQXFx7WViYqUq+9FK9/yjSiSmRFBERkQ5vwwaTRKakwNSpTbd+3HViF8+vep7M3Mxa5dOSp3H96OuVQLaVggJT+/jBB2ZAT08xMab56syZEBLim/hEpNUokRQREZEObdMmWLUKBg9uOoksc5bx2qbXeH/7+9jY7vKEiATuGncXo+NGt33A3VFBASxZYmog6yaQffvCVVfBtGnqQEekC1EiKSIiIh3W5s3w3XemM8+mksiV+1fy4toXOVZyzF0W4BfANSOv4arhVxHgrySm1eXnmxpIbwlk//5w7bUwaZLpGUlEuhQlkiIiItIhbd0KK1bAgAHmnciGchFntZOF6xfywY4PapWf0fsM7hx3JwmRCe0QbTdTVGR6YPWWQCYl1SSQ6oFVpMtSIikiIiIdzrZtpnfW5GSYMaPhJPJYyTH+nPpnth/f7i6LCoritrNuY2ryVI0F2drKysz7j++8U78TneRkk0BOnKgEUqQbUCIpIiIiHUpGBixfblpGNpZErs9Zz5NpT1JYUegum9hvInefczcRQc0YF0Saz+mETz+FN9+EvLzay5KT4brrYMIEJZAi3YgSSREREekwduyAZcsgMRG+/33w96+/jm3bvLnlTd7Y8oa7Qx0/y49bxtzCrKGzVAvZmqqr4ZtvYPFiOHy49rKEBPjxj9WEVaSbUiIpIiIiHcKBAyZnSUhoOIksKC/gf9L+h3WH1rnLYkJi+N2k3zGi14h2jLaLs20z3sqrr8KePbWXxcaaGsgZM7zfJBHpFpRIioiIiM8VFMDSpRAdDRdeCA4v/0LZcXwHj6c+XqtX1jN6n8FvJv2G6ODodoy2i9u1CxYuhI0ba5dHRMA118APfgCBgb6JTUQ6DCWSIiIi4lOVleb1O4CLLvI+1OC6nHU8uvxRKqoq3GU/GvEjbhh9A/5+qhVrFcePwz//CV9+aWokXYKD4fLL4YorIDTUd/GJSIeiRFJERER8xrbhq69M/y0/+AFERtZfJ21fGk+mPYmz2glAWEAYv5rwK85JOKedo+2iyspML6xLlkB5eU25nx/MnAnXXw9RUb6LT0Q6JCWSIiIi4jNr10J2thkxIsHLcI9f7PqCeSvnuTvViQ2N5ZFpj2hsyNZQXQ1ffGFqIU+cqL1s3Di45RbT65GIiBdKJEVERMQndu2Cdetg6FAYNar+8g+2f8BL615yzydEJPCnaX+iV1ivdoyyi8rIgAULYOfO2uUDBsBtt8GZZ/omLhHpNJRIioiISLs7fhy+/hri4mDy5NrLbNvmra1vsXjzYnfZgOgB/HHaH9Wpzuk6cQIWLTLvQXqKiYEbb4Tp0xseuFNExIMSSREREWlXZWWmc52goPrDfNi2zSsbXmFJxhJ32fDY4Tw05SHCAsNhmWRRAAAgAElEQVR8EG0X4XTCBx/AG29AaWlNeUAAXHWVmYKDfRefiHQ6SiRFRESk3VRXw+efm1zmsstqdwJabVczf/V8Ps361F02Jm4MD5z/AMEOJTmnbP1604z1wIHa5RMmmGascXG+iUtEOjUlkiIiItJuVq6EnByYNg16ebzqaNs2z696ns93fe4um9BvAr+Z+BsC/L2MByJNO3YMXnoJVqyoXd6vH/z0pzBmjG/iEpEuQYmkiIiItIsDB2DzZhg5ElJSai97a+tbtZLI6cnTuWf8PRoj8lRUVcGHH8Jrr5l2xC4hIWYojx/+EBz6J6CInB79ioiIiEibq6iAb74xwxGOH1972Re7vqjVsc705Oncd+59WJbVzlF2ATt2wAsvmC5xPc2YATffDD16+CYuEelylEiKiIhIm0tLg+JimDWrdmXY+pz1PLfqOff8mLgx/GL8L5REtlRxsRkP8qOPwLZryhMT4a67TDWwiEgrUiIpIiIibSo721SUnXUW9O5dU777xG4eT32cKrsKgOSoZO4/734cfvrnSbPZNqSmwssvm6E9XAID4dpr4Yor1IxVRNqEfllERESkzZSVwfLl0LMnnH12TfmxkmPM/WYupU4zFEVsaCxzp84lNCC0gT1JPceOwfz5sHp17fKzz4af/Qz69PFNXCLSLSiRFBERkTazfDmUl8Mll9SMc19cUcxDXz1EbmkuAKEBoTw05SF6hvb0YaSdiG2bgTgXLqw9JmRMDPzkJzBpEqhpsIi0MSWSIiIi0iYyM2H3btO5TkyMKXNWO3ls+WPsLdgLgMPPwQPnPUBydLLvAu1McnLguedM97culgU/+AHceCOEhfkuNhHpVpRIioiISKsrKoJvvzWtK884w5TZts2zK59l05FN7vXuOecezog7w0dRdiLV1fD++6ZDnYqKmvKEBLjnHhgxwnexiUi3pERSREREWt2yZSb3mTq1ppXluxnv8lX2V+51bjzjRqYNmOabADuTvXth3jzTY5GLnx9ceSVcd53pWEdEpJ0pkRQREZFWlZ4O+/fD5MkQGWnKMo9n8urGV93rzBw0kx+N+JGPIuwkqqpgyRJYvBiczpry5GS4914YPNhnoYmIKJEUERGRVlNQAN99B/361bS2LK4o5olvn3AP8zEkZgg/HftTjRXZmIMH4a9/hYyMmjKHA2bPhquv1pAeIuJz+hUSERGRVpOWZpqyTpli5m3b5vlVz3O4+DBgemj9zaTfaKzIhtg2fPyx6ZG1vLymPCUF7rsP+vf3XWwiIh70Ky4iIiKtYt8+8zrf+PE1nYd+lvUZqftS3ev84pxf0Cdc4xt6deyYeRdyw4aaMn9/8x7k1Veb7yIiHYQSSRERETlt1dWmNjIqCkaPNmV78/fy0rqX3OvMHDSTyf0n+yjCDsy24euvYcECKC6uKe/fH371Kxg0yGehiYg0RImkiIiInLYtWyA/H2bONB2KljvL+XPqn6moMkNVJEUl8ZOzf+LjKDugwkJ4/nmThbtYFlxxBdxwg3pkFZEOS4mkiIiInJaSEli71lSguV7he3ndy+wr2AdAoH8gv5v0OwL9lRTVsmkTPP00HD9eU9anj3kXcuRI38UlItIMSiRFRETktKxaZUaqmDDBzC/fs5xPsz51L//Z2T8jMSrRR9F1QE6nGdLjnXdMs1aXmTPhttsgONh3sYmINJMSSRERETllR47Ajh1w5pnm/chDRYd4btVz7uXn9z+fCwZe4MMIO5iDB+GppyAzs6YsMtKMC3nOOb6LS0SkhZRIioiIyCmxbfNqX2gonHUWVFVX8eS3T1LqLAUgPjyeu865S+NFgrlYS5fCSy9BWVlN+Zgx8MtfQkyM72ITETkFSiRFRETklGRmmhrJqVNNnzDvZXzIjtwdADj8HPxm4m8IDQj1bZAdQVERvPACpNYMg4LDATffDLNmmc51REQ6GSWSIiIi0mIVFebdyN69ISUFjhYf5bXNr7mXXzfqOlJ6pvgwwg5i+3b4y19Mxu2SkAC//S0MHOi7uERETpMSSREREWmx9etNb60XXghg8+KaFylzmiabSVFJXDn8Sp/G53O2De+/D6+8YnoiclGHOiLSRSiRFBERkRbJz4fNm2HIEFMjmbZvBasOrnIvv2vcXTj8uvE/MQoLYd48WLmypiwsDO65ByZO9F1cIiKtqBv/youIiMipWLEC/P1NJ6MllSUsWLvAvWzmoJkM7zXch9H5mLemrCkp8LvfQVyc7+ISEWllSiRFRESk2XJyYO9eGD/e9Na6YM0/yS3NBSA6OJo5Y+b4NkBfsW147z1YtKh2U9ZZs2DOHNO5johIF6JfNREREWm2NWtMAjlyJOw4voP/ZP7HveyO791BWGCYD6PzkaIieOaZ+k1Z77sPzj3Xd3GJiLQhJZIiIiLSLAcPmhrJiRMBPyfPr3oeGxuAs+PPZnL/yb4N0Bd27YLHH4dDh2rK1JRVRLoBJZIiIiLSLK7ayOHD4f3tH7A7bzcAgf6B/Hzsz7G623iIX35pxoesqKgpU1NWEekm9CsnIiIiTdq/31S6TZ4Mx8uOsHjzYvey60ddT1x4N6p9q6yEv/0NPvqopiwkxDRlVa+sItJNKJEUERGRJq1ZA+HhMGSIzaOp/0t5VTkAyVHJzBo2y8fRtaNjx0xT1h07asoSE+GBByAhwXdxiYi0MyWSIiIi0qh9+8xoFuedB98d/JY1OWsAsLC4+5y7u8+YkRs3mqE9Cgpqys47z4wPGRzsu7hERHygm/zyi4iIyKly1UYOGFzBkx8tdJdfPPhihsYO9WFk7cS24Z134B//MN8B/Pzg1lvhssugu70bKiKCEkkRERFpxJ49cPQonH8+fLzzPxwtOQpAVFAUN515k4+jawdlZTBvHqSm1pT16GF6ZR050ndxiYj4mBJJERERadDatRAZCX2Ti3j4P/9yl1876tquP2bkkSPwyCOwe3dN2YgRJomMifFdXCIiHYASSREREfEqO9v0LTN1Kryz7f8oqigCID48npmDZ/o0tja3ZYvpVMfzfchLLoHbb9fQHiIiKJEUERERL2zbvBsZFQVR8Uf54KMP3MtuOvOmrtvBjm2bYT1efhmqqkyZwwE//zlceKFvYxMR6UC66H8FRERE5HTs3g25uTB9OryxdTGV1ZUApMSkMClxko+jayOVlfDii/DZZzVl0dHw3/8Nw4f7Li4RkQ5IiaSIiIjUYtvm3cjoaPDvmc2Xq790L7tlzC1YXbGX0hMnTFPWbdtqylJSTBIZG+u7uEREOiglkiIiIlLLrl0mr5oxA17duAgbM+TF2PixjI4b7ePo2sCuXfCnP5kXQl2mTYO774bAQN/FJSLSgSmRFBERkVrWrzcjXBSFbWJtzloALCxuHnOzjyNrAytXwlNPmWE+wIwJeeutMGuWxocUEWmEEkkRERFx27/fvBs5ZYrNgo2L3OXTB0wnOTrZZ3G1OtuGJUtg0SLzHSA01Azt8b3v+TQ0EZHOQImkiIiIuG3aZPKpnMBUMnMzAQj0D+THZ/zYx5G1IqcT5s+Hzz+vKevTB/7wB0hM9F1cIiKdiBJJERERAUxN5P798L2xThZs/oe7/NIhlxIb2kU6nCkshMceM+NEuowcaTrViYz0XVwiIp2MEkkREREBTG2kwwF7Az/mUPEhAMIDw7l6xNU+jqyV7N8Pf/wj5OTUlM2YAXfdBQEBvotLRKQTUiIpIiIilJTAzp0wYEgJC3e86S6/ZsQ1hAeG+zCyVrJpk6mJLC6uKbv5ZrjqKnWqIyJyCpRIioiICFu2QHU17A35gILyAgB6hfbikiGX+DiyVvDFF/Dcc1BVZeaDguDXv4YJE3wbl4hIJ6ZEUkREpJurrIT0dEhIKmPx3vfc5TeMvoFA/048jqJtw5tvwuuv15TFxJhOdQYN8l1cIiJdgBJJERGRbm77dqiogCNRH1OYWwhA79DeTEme4uPIToPTCc8/b2ojXZKT4aGHILaLdBwkIuJDSiRFRES6Mds2zVpjelXwfs4Sd/nVI67G4ddJ/5lQXAyPPw4bN9aUjRkD999vxjYREZHT1kn/CyEiIiKtITsbCgrAMXwpJ/afACAmJIYZA2f4NrBTdfQozJ0Le/fWlH3/+3DnnaZLWhERaRX6RRUREenGNm2CsAgnX+S+4y67YtgVnfPdyKwsePhhOHGipuzGG+FHP1LPrCIirUyJpIiISDd1+LCZ/Acv4+jhIwBEBEYwc/BMH0d2CtatM81Zy8rMvMMB994LU6f6NCwRka5KiaSIiEg3tWkTBATYfFf0f+6yy4ddTrAj2IdRnYKvvoJ582qG9wgLgwcegNGjfRuXiEgXpkRSRESkGyoogN27wUpK42DufgBCA0K5JKUTjRtp2/Dvf8OiRTVlvXqZ5q2JiT4LS0SkO1AiKSIi0g1t3gyWZbO+4l/ush+m/JCwwDAfRtUCtg1/+xu8/35NWXKySSJjYnwWlohId6FEUkREpJspLzdjR1b3Wcu+ol0ABPkHcdnQy3wcWTNVVsLTT0Nqak3ZqFHw+9+bZq0iItLmlEiKiIh0MxkZUFlps5Wa2siZg2cSFRzlw6iaqbgYHnvMvODpMmkS/OpXENgJe5oVEemklEiKiIh0I7YN27ZBRY8t7C7aBoDDz8EVw67wcWTNkJtrxojcvbum7Ic/hJ/8BPz8fBaWiEh3pERSRESkGzlwwHS0k9HzX3Cyk9MLBlxAz9Cevg2sKQcPwoMPwpEjNWU33wxXXaUxIkVEfECJpIiISDeSng55/jvYU74BywI/y4+rRlzl67Aat2sX/OEPkJ9v5v384J57YMYM38YlItKNKZEUERHpJoqLYc8e2BX2L3cl3pSkKfQJ7+PbwBqzZQv86U9QUmLmAwPh/vth7FjfxiUi0s0pkRQREekmMjLguHMfe5wrcQSYsh+N+JFvg2rMqlXwxBNQUWHmw8LgoYdg+HDfxiUiIkokRUREuoPqatPJzt6Q991J5LkJ55IYlejbwBry1VfwzDMmcIAePeCPfzRjRYqIiM8pkRQREekG9u6F3KJCdgd/6f6P/6xhs3waU4Pefx9efrlmvk8fk0TGx/suJhERqUWJpIiISDeQng5Z1qf4B5pmogOjBzKy10gfR1WHbcPrr8Obb9aUJSfDww9DTIzPwhIRkfqUSIqIiHRxBQWwZ5+T3QH/cXeyc9nQy7A60rAZtg0LFsB//lNTNny46a01PNx3cYmIiFdKJEVERLq49HTYXfkdzrBj+ANRQVGcn3S+r8OqUVUFzz4LX35ZU3b22aZ31qAg38UlIiINUiIpIiLShVVVwY4dsDvoPfz9TdkPUn5AgH+AbwNzqayEp56CtLSasvPPh1/+Ehz6Z4qISEelX2gREZEubNcu2FO0g7zgDIIBh5+Diwdf7OuwjPJyeOwxWLeupuyii+DOO8HPz3dxiYhIk5RIioiIdGHbtsF23ic42Myf3/98eoT08G1QACUlpifWrVtryi6/HG69FTrSu5siIuKVEkkREZEuKjcXsg7mctCRSphHJzs+V1gIDz0EmZk1ZddfD9deqyRSRKSTUCIpIiLSRaWnw9aK/xASUwXAyF4jGRQzyLdB5ebCgw+agS1dbrvN1EaKiEinoURSRESkC6qshG07Ktjt+JjQk53s+Lw28sgR+P3vISfHzFuWeR9y5kzfxiUiIi2mRFJERKQL2rkTthZ/g39EIQC9Q3szPmG87wLKyYEHHoCjR828nx/8+temh1YREel0lEiKiIh0QenpNhm85x6G8YdDfoi/n79vgjlwAP77v02zVjDDevzXf8F4Hya2IiJyWtS3toiISBdz9ChsPLSZsqA9AAQ7grlw0IW+CWbPHpM0upLIwED4wx+URIqcpuzsbCzLYs6cOc3eZtGiRViWxaJFi5q9zZw5c7Asi+zs7GZvk5ycTHJycrPX7y7mzp2LZVl8/fXXvg6lVahGUkREpIvZvh02VbxHWLSZnzFgBmGBYe0fyK5d5p3IQtO8luBgk0SOHt3+sYiISKtSIikiItKFVFXBmowcjjhW0/Nku6NLh1za/oFs326G+CguNvOhoTB3Lgwf3v6xiAgAV1xxBeeeey7x8fG+DkW6ACWSIiIiXUh2Nqwp+oCwSBuAsfFjSYhMaN8g0tNN0lhaaubDw+GPf4SUlPaNQ0RqiYqKIioqytdhSBehdyRFRES6kM3bythZ9QXBwWa+3Yf82LTJNF91JZGRkfDoo0oiRdpQdnY21157LbGxsQQHBzN27Fg+/PDDeus19o7k0qVLOe+88wgLCyMmJobLL7+cjIyMBo9p2zbPP/88I0eOJDg4mISEBO6++27y8/MbjfWNN95g2rRp9OjRg+DgYIYPH84jjzxCeXl5vXUty2Lq1KkcO3aMO+64g/j4eIKCghg5ciSvvPJK0xfGg+u9zfz8fO6++24SEhIIDg5mxIgRPPvss9i2XWt9z3dQd+zYwezZs+nduzd+fn613nHMzMzkpptuIiEhgcDAQPr27ctNN91EZmZmo/G8+uqrnHXWWYSEhNC7d29uvfVWDh06VG+9tWvXcu+993LmmWcSExNDcHAwKSkp/PrXv+bEiRMtugatTTWSIiIiXURREXy9ezkBoSVgQUJEAmP6jGm/ANavh0cegYoKMx8dbZLI/v3bLwaRbmbPnj2cc845DBw4kBtvvJHc3FzeeustZs2axdKlS5k2bVqT+3j77beZPXs2gYGBzJ49m/j4eFJTU5kwYQJnnHGG123uu+8+nn32WeLj47njjjsICAjgvffeY+XKlVRUVBAYGFhvm9tuu42FCxfSr18/rrzySqKjo/nuu+948MEH+eKLL/j8889xOGqnJ3l5eUyaNInAwECuvvpqysrKePvtt7n11lvx8/Pj5ptvbva1qqio4IILLiAvL49rr72WiooK3nnnHe699162b9/OCy+8UG+brKwsxo8fz5AhQ7jhhhsoLS0lMjISgNWrV3PBBRdQWFjIZZddxogRI8jIyGDx4sW89957fPHFF4wdO7bePv/617/y2WefMXv2bGbOnElqaiqvvPIKX3/9NStXrqRXr17udV9++WWWLFnClClTuOCCC6iqqmLdunU8/fTTfPzxx6xcuZKIiIhmX4PWpERSRESki9ixA7aUf0z4yU52Zg6eiWVZ7XPwtWtN0lhZaeZ79jTzCe3crFa6vbQ0OH7c11E0rmdPmDixdfb19ddfM3fuXB566CF32fXXX8/MmTN58sknm0wki4qK+OlPf4qfnx/Lly+vlfj88pe/5Jlnnqm3TVpaGs8++yyDBg1i1apVxMTEAPDoo48ybdo0cnJySEpKqrXNokWLWLhwIVdccQWLFy8mJCTEvWzu3Lk8/PDDvPDCC9x77721ttu4cSO33XYbCxYswN/f3x3XGWecwRNPPNGiRDInJ4eBAweyZcsWgk6OjfTwww8zbtw45s+fz+zZszm/zti2qamp3H///Tz22GO1ym3b5qabbqKgoIDXXnuNG264wb3srbfe4tprr+XHP/4x6enp+PnVbgTqSgDPOussd5nrWv/Xf/0Xf//7393l999/Py+88IL73F3+/ve/c/vttzN//nx+97vfNfsatCY1bRUREekCbBu+2ZJJgSMThwMC/AKYMWBG+xx89WpTE+lKInv1gscfVxIp0g6SkpL4/e9/X6vsoosuon///qxatarJ7d977z1yc3O5/vrr69WezZ071+s7la5mpQ888IA7iQQIDg7m8ccf93qcefPm4XA4WLhwYa0kEuDBBx+kZ8+eLF68uN52oaGhPP3007USqREjRjBp0iS2bdtGoatX6GZ6/PHH3UkkQExMDA8++GCt8/IUFxdXK0l3SUtLIyMjgwkTJtRKIgFmz57N5MmT2b59O6mpqfW2vfHGG2slkVBzrV9//fVazXyTkpLqJZEAt956K5GRkXz66adNnHHbUY2kiIhIF3DoEKw8/gnh4WZ+cv/JRAS1Q3OnVatM0uh0mvnevc18795tf2wRL1qrpq+zGDNmjNdEIzExkRUrVjS5/bp16wCYMmVKvWVRUVGMGTOGb775ptnbnHfeefWap5aUlLBx40ZiY2O91nACBAUFsW3btnrlKSkp7qaknhITEwHT9LW5TTsdDgcTvTwgU6dOBWD9+vX1lp155pm1Ek8X1zWYPn2612NNnz6d1NRU1q9fX6+Ws6lrvW3bNsaMMa8lVFZWsmDBAt58803S09PJz8+nurravd2BAwcaONu2p0RSRESkC9iQXszOym/oE2rmLx58cdsfdMUK+MtfapLIuDh47DElkSLtKDo62mu5w+GolXA0xNU5TlxcnNflffr0adE2/v7+9OzZs1bZiRMnsG2bo0eP8vDDDzcZk6fGzg+gqqqq2fuKjY31mnS7ztFbR0Hezt9z3YaGUnGV5+Xl1VvW1LX2jGP27NksWbKEgQMHMmvWLPr06eNObJ955hmvnRS1FyWSIiIinVxlJXya8Q2BoeVYfpAUlcSw2GFte9C0NJNEuv4RFx9vksjY2LY9roi0KlfT1cOHD3td7q0nUc9tBg4cWGtZVVUVx48fJ8Gjabtr/bPOOstdk+cLx44do6qqql4y6TpHb814G3rP3LWut+sD5n3MhvbZ1LV2bbNmzRqWLFnCBRdcwEcffURAQIB73erqav7yl7943U970TuSIiIindzOnTYbSz52N2u9ePDFbdvJTmoqPPFETRLZt6+SSJFO6nvf+x5AvearYGrGNmzY0KJtli9fjtPVSuGk8PBwRo4cydatW8nNzW2NsE+J0+kkLS2tXrlrOI+67y02xrWu51Ag3vbpulaeGrvWriFRAHbu3AnAZZddViuJBFi1ahWlrmGWfESJpIiISCf35eYMCvyyCQqCIP8gpiZPbbuDLVtmaiJdTeYSEsw7kUoiRTqlWbNm0aNHD15//XXWrFlTa9ncuXO9NvecM2cOYHpp9UwMy8rKuP/++70e51e/+hUVFRXceuutXpt7njhxol1qK++///5azUFzc3N55JFHALjllluavZ9JkyYxdOhQUlNTefvtt2ste/vtt1m2bBlDhgxh8uTJ9bb95z//We99TNe1vu6669xNV5OTk4H6yeqRI0e46667mh1rW1HTVhERkU4sLw++3v8x4WFmfkrSFMICw9rmYMuWwVNPmS5iAfr1M0N8ePTaKCKdS3h4OC+99BKzZ8/mvPPOqzWO5JYtWzj//PNZtmxZrW0mTZrEL37xC5577jlGjRrF1Vdf7R5HskePHl7fG7z11ltZu3Yt8+fPZ9CgQe6eZXNzc9m9ezfLli3jlltu4cUXX2yzc42Pj6e8vJxRo0Zx2WWXUVlZydtvv01OTg533nlnvU5xGmNZFq+++irf//73mT17NrNmzWLYsGFs376dd999l4iICP7xj3/UG/oD4OKLL2bSpElcc8017mudmppKcnIyf/7zn93rjRs3jkmTJvHvf/+biRMnMnnyZA4fPszHH3/M0KFD6du3b6tcl1OlGkkREZFObH16IVmVqYSdbNY6c/DMtjnQ8uW1k8jERFMTqSRSpNO7+uqr+eSTTzj77LP517/+xYsvvkhMTAwrVqxgwIABXreZN28ezz33HFFRUSxYsIA33niDiy66iKVLlxIYGOh1mxdeeIEPPviACRMmsHTpUp5++mnef/998vPz+c1vfsN9993XlqdJYGAgS5cu5cILL+TNN99kwYIFREVFMW/ePJ5//vkW72/8+PGsXr2a66+/nhUrVvDkk0+SlpbGddddx+rVqxk/frzX7X75y18yf/58NmzYwDPPPENGRgZz5swhLS2N3h6dlfn7+/P+++/z85//nIMHD/Lss8+SmprK7bffzqefflqvuWt7s2zXfxCEsWPH2nWr9EVERDqq6mr49cvvkVb2N3r3hsE9BvPXmX9t/QMtXw5PPlk7iXzsMWigN0URkY7G1Uw0Ozvbp3F0BpZlrbVte2xT66lGUkREpJPat89mXYFHJzspbTDkR2pq/ZpIJZEiIt2eEkkREZFO6tMNmymwDxASAqEBoZyf1Pz3e5olNdXURLo61lESKSIiJymRFBER6YTKyuDTXR8TFgaWBdOSpxHsCG69AyiJFBGRRqjXVhERkU5oXXoeWeUr6HOyr5tW7WTn22/rJ5GPPqokUkQ6Lb0b2fpUIykiItIJ/Xvj5zgCqwgIhOGxw0mOTm6dHael1R4n0jXER48erbN/ERHpEpRIioiIdDLHj9t8d/QT99iRFw9upU52vvuufhL52GNKIkVEpB4lkiIiIp3Mh2vXUVh9hNAwiAiMYFL/Sae/01Wr4IknoKrKzCckKIkUEZEGKZEUERHpRGwbPtr+GcEh4O8P0wdMJ9Df++DfzbZmDTz+ODidZr5vXyWRIiLSKCWSIiIinci23XlsL17pbtZ60aCLTm+H69aZpNGVRMbHm/mYmNPbr4iIdGlKJEVERDqRd9Z9BX5VhISYTnYSoxJPfWcbNpiOdCorzXxcnEkie/ZsnWBFRKTLUiIpIiLSSVRW2nyR/SmhoWD5wYWDLjz1nW3aBH/6E1RUmPnevU0SGRvbOsGKiEiXpkRSRESkk/hiUwa5zgOEhUGwI5jJ/Sef2o62bIE//rEmiYyNNTWTvXu3XrAiItKlKZEUERHpJJZs/AyHA4KDYErSFIIdwS3fybZt8PDDUF5u5nv2NDWRffq0brAiItKlKZEUERHpBI7ll7Dm6HLCwgALvj/w+y3fyY4d8NBDUFZm5mNiTE1kfHyrxioiMmfOHCzLIjs729ehSBtRIikiItIJ/N+q5VTa5YSFQVJUEkN6DmnZDrKy4A9/gNJSMx8VZZLIhITWD1ZE2kV2djaWZTFnzhxfhyLdkBJJERGRTuDj7Z8RFAgBAaY20rKs5m+8ezc8+CAUF5v5yEiTRPbr1zbBisp2DBQAACAASURBVIhIl6dEUkREpIPbkJ1NdtEOwsLA4edg2oBpzd947174/e+hsNDMh4fDI49AUlLbBCsiIt2CEkkREZEO7q3Vn2NZEBYG5yacS2RQZPM2PHAAHngACgrMfFiYGfJjwIC2C1ZE2sXcuXMZcPJv+dVXX8WyLPe0aNEiAKqrq3nxxRcZN24c4eHhhIWFMW7cOP73f/+X6urqevu0LIupU6dy6NAhbr/9dhISEvD393fvD6CkpIQnnniCsWPHEhERQXh4OMOHD+eee+7h8OHDXmNdsGABo0ePJjg4mLi4OO644w7y8/Nb/ZpI+3L4OgARERFpWIWzkm/2fkVIMPj5w0WDL2rehjk58N//DXl5Zj4kxPTWOnhw2wUrIu1m6tSp5OXlMW/ePM4880wuv/xy97IxY8YAcOONN/L666+TmJjI7bffjmVZLFmyhDvvvJPU1FQWL15cb7+5ubmce+65hIeHc+WVV+Ln50dcXBwAJ06cYNq0aWzcuJGhQ4dy6623EhgYSFZWFgsXLuTKK690r+vy29/+lk8//ZRLL72UCy+8kK+++oqXX36ZnTt38uWXX7bhFZK2pkRSRESkA/tww0qKKgvpFQW9Q3tzZtyZTW90+LBJInNzzXxwMMydC0OHtmmsIh3BpW9c6usQmu2D6z445W2nTp1KcnIy8+bNY8yYMcydO7fW8jfeeIPXX3+ds846i2XLlhEeHg7AI488wpQpU3j99de55JJLuP7662ttt3nzZm688UYWLlyIw1E7VbjrrrvYuHEjP/vZz3jhhRfw86tp3FhYWOi1lvO7775j8+bN9O/fHwCn08n06dP56quvWLVqFeecc84pXwPxLTVtFRER6cCWbP4UPz8ICYXvD2pGJzvHjpkk8tgxMx8YaHprHTGi7YMVkQ5j4cKFAPz5z392J5EAYWFhPPHEEwD87W9/q7ddYGAgTz31VL0k8siRI7z11lvEx8fz1FNP1UoiASIiIoiKiqq3vz/84Q/uJBLA4XBwyy23ALBq1apTPDvpCJRIioiIdFAH8o6w+chGQkPBz7KYMWBG4xvk5pok8sgRMx8QYHprHT267YMVkQ5l3bp1+Pn5MXXq1HrLpkyZgr+/P+vXr6+3LDk5md69e9crX716NdXV1Zx//vmEhYU1O46xY8fWK0tMTARMU1npvNS0VUREpIN6c9XnVNs24WHwvfjv0SusV8Mr5+eb3llzcsy8w2GSypPvSol0F6fTXLQryc/PJyYmhsDAwHrLHA4HsbGxHHH9TycPffr08bq/vJPvWye0cOzZ6Ohor8cHqKqqatG+pGNRjaSIiEgHVG1X80nmUv4/e3ceH1V1/3/8NTPZVxIg7CTs+yK77KCgoqAsIkq1it9Wq1artlaqVtxR24rVota2uNQiivwQKouoYRNQFlkFZItAQEIWQvZkZu7vj9PMJCRAgCQzSd7Px+M+Zu65d+79DPFBeHvOPScgAIKDzdqRZ5WVZULkkSNm326H3/8eyukJEJG6ITo6mvT0dIqKisocczqdpKamEhVVdgbosw2fLw6EycnJlVuo1FgKkiIiIn5o3cHvSMlKJTwcokKi6N+8f/kn5uSYZyCTksy+zQa//S0MGFBttYqIbzgcDqD8nr3LLrsMt9vN6tWryxxbvXo1LpeLXr16Vfhe/fr1w263s3r1anJyci6+aKk1FCRFRET80MdbVmBhln4cmTCSAHs5T6Pk5cGTT8L+/WbfZoMHH4QhQ6q1VhHxjZiYGGw2G4cPHy5zbNq0aQBMnz6d3NxcT3tubi6PPvooAHfeeWeF79WwYUOmTJnC8ePH+e1vf1tmhtbs7GytDVnH6BlJERERP5OZn8mGI98QHGzmyxndZnTZk/LzzbqQe/d62+69F0aMqL5CRcSnIiIi6N+/P2vWrGHq1Km0b98eh8PBuHHjuOWWW/j000/56KOP6NKlCzfccAM2m42FCxdy6NAhJk+ezNSpUy/ofq+//jo7d+7kzTffZOXKlVx11VUEBQVx6NAhli9fzqJFi8qd3EdqJwVJERERP7N450ryCp3ExkDH+h1pEd2i9AmFhfDcc7Brl7ft7rvhqquqt1AR8bn333+fBx98kGXLljF37lwsy6J58+Z0796duXPnMmzYMP71r3/x1ltvAdCpUycefvhhfvWrX13wvWJiYli3bh2zZs1i3rx5/P3vf8fhcNCiRQumTZtGZy0zVKfYLMvydQ1+o0+fPtamTZt8XYaIiNRhlmVx4zv3se/EYZo1hwcvv59RbUpMtFNUBM8/DyV/X915J9xwQ/UXKyIitY7NZttsWdZ5Z2vTM5IiIiJ+ZF/afg6mHSYkFMKCghnccrD3oNMJL71UOkTeeqtCpIiIVDsFSRERET/yydYVOJ1mkp3BLQcTGhhqDrjd8Je/wIYN3pNvugkmT/ZNoSIiUqcpSIqIiPiJAmcBK/atwm6DsNASa0daFrz6KqxZ4z15/Hi4wIkyREREKouCpIiIiJ9Y++N60rNyCQ2DplFN6NywswmRs2fDV195T7zuOrjjDrPch4iIiA8oSIqIiPiJBdtW4HZDRLjpjbQB/OMfsGyZ96TRo+GXv1SIFBERn1KQFBER8QMnsk+w+eh2HA4ICbExMmEEvPceLFrkPWnECLNWpEKkiIj4mIKkiIiIH1j6wxfk5UF4GPRp2pv6i1bA/PneEwYPhgceALt+dYuIiO8F+LoAERGRus5tufl0xxdYFoRHwJQ9AfDZf7wn9O8PDz8MDofvihQRESlBQVJERMTHtv20jeT0VAIDYfSe07Tbsd47fLVXL/j97yFAv7JFRMR/aHyMiIiIj/139wryC2BEUgo3fn0Ke3GI7N4dHnsMAgN9W6CIiMgZFCRFRER8KKsgi8R96+m/P5Ub1ybRIKyBOdCpEzzxBAQF+bZAERGRcihIioiI+NCqH1fRavsJbt1wiIjgcMICw6BdO3jySQgJ8XV5IiIi5VKQFBER8aGdC97jZ4kHCbBbNAhrCK1awVNPQXi4r0sTERE5KwVJERERHzn61UIGzl2N3bIIDLAT2647PPMMREb6ujQRqSWGDx+OrYJrzyYlJWGz2bj99turtiipFRQkRUREfGHbNoqeeQqryMLhgKCW8QTOfAmio31dmYiIyHkpSIqIiFS3nTtxPzWDk6dSwILTMcEEPP8ixMT4ujIREZEKUZAUERGpTnv3wlNPkXE6hcIiJ6fCg1h+52A6dxrq68pEREQqTEFSRESkuuzfb2Zjzc/nZM5JMoKD+Of4jlzeZ1yFn2ESESm2aNEirrjiCpo0aUJwcDBNmzZl2LBhzJ49+7yf/eqrr4iOjqZp06Zs3br1vOfn5ubywgsv0LNnT8LDw4mIiODyyy9n7ty5Zc4tLCzk9ddfZ8yYMcTHxxMcHExsbCxXXnklS5cuLff6CQkJJCQkcPr0aR566CESEhIIDAxkxowZAMyYMQObzcbKlSuZP38+/fr1IywsjNjYWKZMmUJycvJ5v4NUrgBfFyAiIlInHDpk1oXMyaHAVcBRK5e/juqIrWkoI1uN9HV1IlLD/P3vf+euu+6icePGjB07lgYNGpCSksL27duZM2cO99xzz1k/+8EHHzBt2jRat27NsmXLiI+PP+e9Tp06xciRI/nuu+/o1asX06ZNw+12s3z5cm655RZ27drFs88+6zk/PT2dBx54gIEDBzJq1CgaNmzI8ePHWbx4MWPGjOHtt9/m//7v/8rcp7CwkJEjR5Kens7o0aOJioqiVatWpc6ZPXs2ixYtYty4cQwbNoxvvvmGefPmsW3bNrZu3UpwcPAF/knKxVKQFBERqWpHjpgQmZ0NwHGyeX10B9KiQrk2vidx4XE+LlCkFhk71tcVVNzixRf90bfeeougoCC2bdtGXFzpv0NSU1PP+rmXXnqJRx99lIEDB7Jo0SJiY2PPe6/f/OY3fPfdd7z44os88sgjnvb8/HxuuOEGnn/+eSZNmkTPnj0BiImJ4ccff6R58+alrpOZmcmgQYN45JFHmDp1KqGhoaWOHz9+nM6dO7Nq1SrCz7IE0rJly9i4cSPdunXztN1yyy3MnTuXTz/9lMmTJ5/3+0jl0NBWERGRqnTsGDz2GGRmAmCFh/HamCYcCgsjPByuajvaxwWKSE0VEBBAYGBgmfYGDRqUaXO73dx33338/ve/Z/z48XzxxRcVCpFpaWn8+9//pk+fPqVCJEBISAgvvvgilmXxn//8x9MeHBxcJkQCREdHM23aNDIyMti4cWO59/vzn/981hAJcP/995cKkQC/+MUvAPj222/P+32k8qhHUkREpKqcOGFCZEaG2Q8J4ft7b2LT93OwgEb1IunfrL9PSxSRmmnq1Kk8/PDDdOnShZtuuolhw4YxaNAgGjZsWO75EydOZOHChfz6179m1qxZ2O0V60/auHEjLpcLm83meV6xpKKiIgB2795dqn3Xrl28/PLLrF69muPHj5Ofn1/qeHnPNIaEhNC9e/dz1tOnT58ybS1atAAgo/jvWqkWCpIiIiJV4eRJ+MMfoHiIWXAwzJjB4ozF5ORAcBBc3WEkgY6yvQkicgkuYbhoTfLQQw/RoEEDZs+ezV//+ldmzZqFzWZj2LBhvPzyy2UC1+rVqwkICGDs2LEVDpFgeiTBBMqz9SICZP9v6D7Ahg0bGDlyJE6nkyuuuIJx48YRFRWF3W5n69atfPrppxQUFJS5Rlxc3HknHqtXr16ZtoAAE2lcLleFvpNUDg1tFRERqWxpaaYnMiXF7AcFwR//SGab5qw59A2FhRAeDqPbaFiriFy82267jQ0bNpCWlsZnn33GnXfeyerVq7nqqqtIKf77538SExOJiYlh7NixfPbZZxW+R3R0NAAPPvgglmWddUtMTPR85tlnnyUvL4/PP/+cpUuXMmvWLJ5++mlmzJhB//5nH4Wh2atrFgVJERGRypSRYULk8eNmPyDA9Ex2705iUiKZWU5sNujZogMto1v6tlYRqRXq1avnmQ319ttvJz09nTVr1pQ6p3v37qxatYrY2FgmTJjAwoULK3Ttfv36Ybfby1zvXPbv309sbCzDhw8vc2zVqlUVvo74NwVJERGRypKZaUJk8bM/DgdMnw69e2NZFssPfE5uDoSEwLUdrvJtrSJSoy1btgyn01mmvbgnMiwsrMyxTp06sXr1aho1asSNN97IvHnzznufuLg4pk6dyqZNm3jmmWfKveeBAwc4dOiQZz8hIYH09HS2b99e6rx//vOfLF++/Lz3lJpBz0iKiIhUhqwsePxxs9QHgN0OjzwC/foBsCd1D/tPHMHpgsZRIQyJH+LDYkWkppsyZQohISEMHjyYhIQELMtizZo1bNy4kd69e3PllVeW+7m2bduyZs0aRo4cydSpUykoKOC22247571ef/119u3bxx//+Efef/99Bg8eTKNGjTh27Bi7d+9m48aNzJ0717Pm429+8xuWL1/O4MGDmTx5MtHR0WzatIm1a9cyadIk5s+fX+l/HlL91CMpIiJyqbKzTYhMSjL7Nhv89rcwcKDnlBUHV5CTY/LlqI5DCAkI8U2tIlIrzJw5k8svv5wtW7Ywe/Zs5syZQ1FRES+++CKJiYnlLgtSLD4+ntWrV9O2bVvuuOMO3n777XPeKyoqilWrVvHaa6/RoEEDPvnkE/7yl7+QmJhIZGQkr7zyCqNGjfKcf/XVV7N48WI6d+7MvHnz+Oc//0lwcDCJiYlce+21lfZnIL5lsyzL1zX4jT59+libNm3ydRkiIlKT5OTAE0/Avn1m32aDBx+EESM8p+QW5XLrgts4kFRAWDjMmfInOjTo4KOCRUREzs5ms222LKvsOitnUI+kiIjIxcrLgxkzvCES4P77S4VIgDU/riEjqwC3Be0btaR9/fbVW6eIiEglU5AUERG5GPn58NRTsGePt+3ee6Gc55JWHFxBTraZwPWGbqM1xb2IiNR4CpIiIiIXqqAAnn4adu3ytt11F1x9dZlTk04l8X3KXvLzISoigJGtRpQ5R0REpKZRkBQREbkQhYXwzDOwY4e3bdo0uO66ck9fccBMsmMBw9sOICo4qnrqFBERqUIKkiIiIhVVHCK3bfO23X47jB9f7ulFriISkxLJyYHgYLihq9aOFBGR2kFBUkREpCIKC+H552HrVm/bbbfBxIln/ciGoxtIz86isBBaxMbRo1GPaihURESk6ilIioiInE9REbzwAmze7G2bOhVuvPGcH/v8wOdk55gVQW7oNkqT7IiISK2hICkiInIuTifMnAkl1xm++WaYMuWcHzuRfYKtP20lJwdCQ22M6Vh2NlcREZGaSkFSRETkbJxOePFF+PZbb9vkySZInseKgyvIzweXC/q36EWDsAZVWKiIiEj1UpAUEREpj9MJL78MGzZ42yZNgp/9zIxVPddH3U7PsFa7HSZdNrqKixUREaleCpIiIiJnKg6R69Z528aPN5PrVOA5x2+TvyUtN4O8XGgcHcvlLftVYbEiIiLVT0FSRESkpPJC5PXXwx13VChEAizZt4TcXHBbMK7LaALsAVVUrIiIiG8oSIqIiBQ7W4i8884Kh8jk08lsO7GN7GwICrRxo4a1iohILaQgKSIiApUSIgGWH1hOUREUFED/5n1pGN6wCooVETm3hIQEEhISfF2GX3nnnXew2Wy88847vi6lVlCQFBERqaQQWegq5IuDX5CTDTbglr5jKr9WEZFqZLPZGD58uK/L8CtJSUnYbDZuv/12X5fiU3poQ0RE6rZKCpEAXx/+mtMFWWTnQOOoOC5vdVklFysiIhdr/PjxDBgwgCZNmvi6lFpBQVJEROquSgyRAEv3L/WsHTmu09XYbRr4IyLiL6Kjo4mOjvZ1GbWGfsOJiEjdVMkhMulUErtTd5OTDYGOAG7uP6oSixURKcuyLF5//XW6dOlCSEgIzZo147777iMzM7Pc8zMzM3n55ZcZOXIkzZs3JygoiIYNGzJu3Dg2lFwzF+/zhACrVq3CZrN5thkzZpQ6b+LEibRu3ZrQ0FCioqIYNGgQ//73vy/ou5R8fvGzzz5j4MCBhIeHExMTw6RJk9i3b1+5nzt+/Dj33nsvCQkJnu8zYcIENm/efM57lFT8PGlubi6/+93vaNmyJcHBwbRt25YXX3wRy7I8586YMYNWrVoB8O6775b6cym+rmVZvPvuuwwcOJCGDRsSEhJCixYtuOqqq5g3b94F/bn4M/VIiohI3eN0wsyZ8M033rZLCJEAS/ctxe2C3DwY3OJyYsPqVVKxIlJV3G43hw8fJiIiggYNGlzUNQoKCkhOTqZBgwZERUVVcoXn9pvf/Ia//vWvNGnShF/+8pcEBgby6aef8s0331BYWEhQUFCp83fv3s1jjz3G0KFDufbaa4mJieHw4cMsWrSIpUuXsnjxYq6++moAevbsyZNPPslTTz1FfHx8qecBSz4z+atf/YrOnTszdOhQmjRpQlpaGkuWLOHWW29l7969PPPMMxf0nRYsWMDSpUsZP348w4cPZ+vWrXzyySckJiaybt06OnTo4Dn30KFDDB48mGPHjjFy5Ehuvvlmjhw5wscff8xnn33GJ598wnXXXVeh+xYVFTF69GiOHTvGNddcQ0BAAAsXLuTRRx8lPz+fJ5980vPdT506xauvvkqPHj244YYbPNfo2bMnAI899hgvvPACrVq1YvLkyURHR3P8+HE2btzIxx9/zE033XRBfyZ+y7Isbf/bevfubYmISC1XWGhZTz1lWddd593+8Q/Lcrsv+pK5hbnWpI8mWcPevM7q9sJ11pq92yuxYBGpKp9++qn16KOPWo8//rh15MiRC/68y+Wy3njjDWv69OnW888/b2VlZVVBleX7+uuvLcBq06aNlZaW5mnPy8uzBgwYYAFWfHx8qc+cOnXKOnnyZJlrHTlyxGrSpInVsWPHMscAa9iwYWetY//+/WXaCgoKrJEjR1oBAQHW0aNHK/R95syZYwEWYC1evLjUsVmzZlmANXLkyFLto0ePtgDr2WefLdX+9ddfWw6Hw4qNjS31Mym+x5w5c0qdHx8fbwHWNddcY+Xm5nraT5w4YUVHR1vR0dFWYWGhp/3QoUMWYP385z8v97vExsZazZo1s3JycsocK+/P398Am6wKZCcNbRURkbqjsBCeew42bvS2TZwI06ZddE8kwKofV5HvzCc7B5qEN2dQu66VUKyIVBbLsti2bRurVq0iOzvb0753717i4uIoKioiJSXlnNcoKipi/fr1rF+/nqKiIgDy8/M5fPgwLVu25PTp06Snp1fp9yhpzpw5gOn9io2N9bSHhITwwgsvlPuZ6OjocntemzdvzqRJk9izZw+HDx++oDratGlTpi0oKIh7770Xp9PJl19+eUHXGzlyZJlexPvuu482bdrw1Vdf8eOPPwJw9OhRPv/8c1q2bMkjjzxS6vyBAwdy8803k56ezoIFCyp877/+9a+EhoZ69uPi4rj++uvJzMxk7969F/Q9AgMDcTgcZdovtufbHylIiohI3VBYCM8+CyWfm5k8GX7+80sKkZZlsWTfEgoLzS3GdrzG81yRiPiHvXv38sEHH7B06VLmz5/vab/yyitJT0+ncePGtG3b1tO+ZcsWPvzwQ5KSkjxtq1evZsGCBSxYsIDVq1cDEBYWxuDBgzl8+DAdOnSgadOmALhcLhITE5k/fz6pqalV8p22bNkCwLBhw8ocGzJkCAEB5T/B9vXXXzN58mRatGhBcHCw5/m+1157DYDk5OQLquPw4cPce++9dOzYkbCwMM/1Jk6ceFHXK+/7OBwOBg8eDMB3331X6nXIkCEEBgaW+czIkSNLnXc+0dHRpf4bKNaiRQsAMjIyKnQdgKlTp5KUlESXLl2YPn06y5YtO+tzqzWZnpEUEZHar6AAnnkGtm3ztk2ZArfcckkhEuCHtB84dOqQmWTHHsTNA0ZeYrEiUtkKCgqwLIvw8HCysrI87Zdddhldu3bF4XBgt5v+lZ9++on58+cTFhbG3r17mT59OkFBQeTk5HgCS05OjucaY8aM4corryQwMNDzP5F2797NkiVLCA0NJTU1lbvvvrvSv1NxMGnUqFGZYw6Hg/r165dp/3//7/8xadIkQkJCGDVqFG3atCE8PBy73c7KlStZtWoVBQUFFa7h4MGD9OvXj4yMDIYMGcLo0aOJjo7G4XCQlJTEu+++e0HXO9v3AWjcuDHg/d7Fr2dbyqO4/dSpUxW6b7165T/XXhzIXS5Xha4D8Morr9CmTRv+9a9/MXPmTGbOnElAQABjxozhz3/+c7mBtSZSkBQRkdotPx+efhp27PC2TZ1qgmQlWLp/KZYF2TkwqPFQ6kdGVMp1RaTyFE8Gc/LkSc9kMsXO7M0qDoNut7vU6ILhw4d7hsWWnGwGKDOpzdmuUZmKl7E4ceIErVu3LnXM5XKRlpZGs2bNSrU/8cQTBAUFsWnTJjp16lTq2F133cWqVasuqIa//OUvpKWlMWfOnFKT8QDMnTuXd99994KuB+b7lOenn34CvN+7+LW4/UzHjx8vdV51cjgcPPDAAzzwwAOkpKSwdu1aPvzwQz7++GN27drFrl27CA4Orva6KpuCpIiI1F55eSZE7tzpbbv1VjOktRJkFWSx5vAa8nLB7Yabel9TKdcVkcoVGBjI2LFjK3Ruo0aNuPnmm/nhhx/o27evJyRGRUVxyy23VOganTp14oYbbiA1NZUhQ4ZcdN3n0qtXL7Zs2cKqVavKBMk1a9bgdDrLfGb//v106dKlTIh0u92sXbu23PvY7faz9sbt378fwDOMtaQLDaXn+pzL5fLUd9lll5V6Xbt2LU6ns8xQ3sTERMD8OVW24mcfK9JLGRcXx4QJE5gwYQJXXHEFX331FTt37qR3796VXld10zOSIiJSO+XkwBNPlA6Rt99eaSES4KtDX1HoKiQ7B5qGtGFwp3aVdm0R8Z1u3boxceJEWrZseVGft9vtDBo0iOuvv77URDiVqbgH8Lnnnis1yU9+fj7Tp08v9zMJCQns27ePY8eOedosy+Kpp57i+++/L/cz9evX58iRI2e9HsDKlStLtS9fvpx//OMfFfwmpX311Vf897//LdX2+uuvc+DAAUaMGEF8fDxgJggaNWoUSUlJzJo1q9T533zzDf/5z3+IiYlh/PjxF1XHucTExGCz2cqdmKigoIAvv/yy1NqTYCZrKv45hYWFVXpNvqAeSRERqX2yskyIPHDA23bnnVBiva9LZVkWS/cvxeWE/DwY0/0a7HZNsiMi1WPQoEH8+te/5rXXXqNr165MmjTJs45kTExMuc8OPvjgg9x9991cdtllTJw4kcDAQL7++mu+//57xo4dy+LFi8t85oorruDDDz9k7Nix9O7dm4CAAIYOHcrQoUO55557mDNnDjfeeCMTJ06kWbNm7Ny5k2XLljF58mTmzZt3wd9r7NixjB8/nvHjx9O2bVu2bdvGkiVLiI2NZfbs2aXOffPNNxk0aBC/+93v+Pzzz+nTp49nHUm73c6cOXOIjIy84BrOJyIigv79+7NmzRqmTp1K+/btcTgcjBs3jpYtW3LllVeSkJBA//79iY+PJz8/nxUrVrB7927GjRtXpke4plKQFBGR2uXUKRMiS8y2yN13w7XXVupttp/YTnJWMjk5EGgLZcqAsjMNiohUpVdffZX27dvzt7/9jbfeeov69eszfvx4nn/+eXr06FHm/Lvuuovg4GBmzZrFu+++S2hoKEOGDGHOnDl88skn5QbJV199FZvNxpdffsmSJUtwu908+eSTDB06lO7du5OYmMjjjz/OkiVLcDqd9OjRgwULFlCvXr2LCpITJkzgl7/8Jc899xyfffYZgYGBTJgwgRdeeIH27duXOrd169Zs2rSJZ599liVLlrBy5UqioqK4+uqreeyxx+jbt+8F37+i3n//nhRXuQAAIABJREFUfR588EGWLVvG3LlzsSyL5s2b06lTJ1588UUSExNZt24dCxcuJDIykjZt2vDGG28wbdq0KquputnO7Haty/r06WNt2rTJ12WIiMjFSkuDxx6D4unmbTb49a9h1KhKv9XTq55m47GNHEuGAbHX8bdpd1X6PURE6op33nmHO+64o9yJe6R62Wy2zZZl9TnfeeqRFBGR2iElxYTI4hn87HZ48EE4Y3bFypB8OpmNxzZSkA9FTpjSq2KTeIiIiNQWCpIiIlLzHT9uQuTJk2bf4YBHHoGBA6vkdot/MMO/srOhTUhfBnRpWiX3ERER8VcKkiIiUrMdPWpCZPGshQEBMH069OtXJbfLLszmi4Nf4HZBTi5c3/0GzliGTkREpNZTkBQRkZrr4EH44x8hM9PsBwXB44/D/9YXqwqfH/icAlcB2TkQa0/gur7dquxeIiJ1xe23365nI2sYrSMpIiI105498Ic/eENkSAg89VSVhkiX2+Ud1poFw5uMo0EDLfkhIiJ1j3okRUSk5tm6FZ57DvLzzX54OMyYAR07Vult1x9dT2puKvn5EOCKZlIfLfkhIiJ1k4KkiIjULN98AzNngtNp9qOj4ZlnoFWrKr/1p3s+BUxvZM+Ia+jYLqjK7ykiIuKPFCRFRKTmWLkSXnkF3G6z36ABPPssNGtW5bfem7qXPWl7cLkgPy+AiQPH4HBU+W1FRET8koKkiIjUDEuXwhtvgGWZ/SZNTIiMi6uW2y/auwgwS360CxpG/+4x1XJfERERf6QgKSIi/u+TT+Cdd7z78fFmOGtM9YS51NxU1h5ZC5YJkle1Hkd0dLXcWkRExC8pSIqIiP+yLHj/ffj4Y29bu3ZmdtbIyGor47MfPsNtucnLh0Z0Y+Rlravt3iIiIv5IQVJERPyT2w2zZ8Py5d62rl3NupGhodVWRr4zn2UHlgGQlQXX1Lue+Phqu72IiIhfUpAUERH/U1QEf/oTrFvnbevbFx59FIKqd6bUxEOJZBdm43RCUEFjxgzsi12rMIuISB2nICkiIv4lL8+sEbltm7dtxAi4/34IqN5fW5Zl8ele75IfPULH0bmTUqSIiIiCpIiI+I/Tp2HGDNi3z9t2/fVw551gs1V7OVuObyE5KxnLgsLcMEZ3uZKIiGovQ0RExO8oSIqIiH84eRKeeAKSk71tt94KN97okxAJsHDPQgByc6FDwGgu61p9z2aKiIj4MwVJERHxvSNHzCQ6qalm32aDe+6Bq6/2WUn70vax9cRWAHKybQysfx3Nm/usHBEREb+iICkiIr61d69ZziMry+wHBMDDD8PgwT4t66NdHwFm3p/m7iEM6NbIVx2jIiIifkdBUkREfGfjRpg5EwoLzX5ICDz2GPTs6dOykk4lsSF5A2Am2RkRNpkOHXxakoiIiF9RkBQREd/4/HN4/XWwLLMfFQVPPgnt2/u2Lry9kZYbGjsvp2+n+OpculJERMTvKUiKiEj1siyYNw8++MDb1qiRGd7arJnv6vqf5NPJrD28FoDsHBgQOJnOnX1clIiIiJ9RkBQRkerjcsGbb8KyZd621q3Nkh8xMT4rq6SPv/8YCwssaFjUhy5N29K4sa+rEhER8S8KkiIiUj0KCuDll+Gbb7xtPXvCH/6Av4wbPZF9gsSkRADy8qCv7Sa6d/dxUSIiIn5IQVJERKpeVhY8/TTs2eNtGzEC7r/fzNLqJ+Z/Px+35QYgtqg7bet1pFUrHxclIiLih/znt7eIiNROP/1khq4mJ3vbJk6En/8cf1pPIzU3lS8OfQFAYQFc5rqJbt3AbvdxYSIiIn5IQVJERKrO3r3wzDOQmWn2bTb4xS9g7Fjf1lWOBbsX4HQ7Aajn7ESrsG5a8kNEROQsFCRFRKRqrFsHf/6zd43IwEB46CEYPNi3dZXjVP4plh9YDoDTCe0KbqJTbxtBQT4uTERExE8pSIqISOWyLPj0U/jXv7xrREZGwhNPQKdOvq3tLBbuWUihywTeaGdb4oN60bWrj4sSERHxYwqSIiJSeVwuePtt+Owzb1vTpuYZySZNfFbWuWQVZPHZPlOv2w1tC26iTXsbERE+LkxERMSPKUiKiEjlyM+Hl16CjRu9bZ07w+OPmx5JP7Vo7yLynfkARLrjaWHrryU/REREzkNBUkRELl16ulne48ABb9vQofDAA/jzg4Y5hTks/mExYEbhtiuYTLNmNho08HFhIiIifk5BUkRELs3BgyZEpqV52268EW691a+W9yjPf3/4LzlFOQBEWE1p5hqs3kgREZEKUJAUEZGLt369mZm1oMDs2+1wzz1w1VW+rasCMvMz+WT3J579jq7JxMbYadHCh0WJiIjUEAqSIiJy4SwL5s+H997ztoWHw6OPQs+evqvrAny480PynHkAxDpa0Pj0cLr38/tOVBEREb+gICkiIhemqAheew0SE71tTZrAH/8IzZv7rq4LcCzrGEv3L/Xs97LfTliog3btfFiUiIhIDaIgKSIiFZeZCc89B7t3e9u6dYPp0/16ZtYzvbv1XVyWC4C2UV0JOdqXLn3A4fBxYSIiIjWEgqSIiFRMUhI88wykpHjbRo+GX/0KAmrOr5PdJ3ez7ug6z35fxzTyAmx06eLDokRERGqYmvObX0REfOebb+BPfzJrRYJ5kPDOO2HcuBr1UKFlWczZOsezP6DxUHIPtKNjRwgJ8WFhIiIiNYyCpIiInJ1lwbx58MEH3raQEHjkEejb13d1XaT1R9ezO9UMyw2wB9DVfSsnqTHzA4mIiPgNBUkRESlfXh688opZ4qNYXBw88QQkJPisrIvldDt5d+u7nv0rWlzLye8b07EjRET4sDAREZEaSEFSRETKOn4cnn0WDh/2tnXvbpb3qEGT6pS0fP9yjmUfAyA8MJx2BTdxBLjsMt/WJSIiUhMpSIqISGnffQcvvgg5Od6266+HO+6osdOa5hblMnfnXM/+2NaTObIlkk6dzPKXIiIicmEUJEVExLAsWLgQ5swx7wECA+G++2DkSN/Wdok++f4TMgsyAWgY1pBGmdfxo029kSIiIhdLQVJERMxsrK+/DqtWedvq14fHHoN27XxXVyVIy01j4d6Fnv0JbW/l0LogunaFsDAfFiYiIlKDKUiKiNR1ycnwwgvw44/etk6dYPp0iInxXV2V5IMdH1DoKgSgdb3WhKcMx+GAHj18XJiIiEgNpiApIlKXrVsHs2aZGVqLXX013HUXBNT8XxEHMw7yxcEvPPuT2k5jz0ob3bqpN1JERORS1Px/JYiIyIVzueC992DBAm9bYCDccw9ceaXv6qpEbsvN69++joV53rN3k94UHemh3kgREZFKoCApIlLXnDoFL70EO3Z42xo1gj/8AVq39l1dlWzx3sXsS98HQKA9kMltf8HaJdCzJ4SG+rg4ERGRGk5BUkSkLtm9G2bOhPR0b1vfvvDQQxAR4bu6KllKTgr/3vFvz/6UrlM4vrcZgYFmOUwRERG5NAqSIiJ1gWXBokVmaQ+Xy7TZbDB1KkyebN7XEpZlMXvjbPKd+QDER8czvNEEFn5tlvsICfFxgSIiIrWAgqSISG2XlQWvvgrffONti4yE3/2uVi6kuObwGjYf3wyADRv39buPbd8FqDdSRESkEilIiojUZnv2wIsvQmqqt61dO3j0UYiL811dVSSrIIu/b/67Z39MuzE0tHVk9SHo1QuCg31YnIiISC2iICkiUhtZlpmR9b33wO32tl9/Pdx+e61Y2qM8c7bOIbMgE4D6ofW5rcdtrFwBQUHqjRQREalMtfNfEiIiddnp0/CXv8Dmzd628HB48EHo3993dVWx7Se2s+LgCs/+r/r8ipPHwjh6FC6/3IRJERERqRwKkiIitcmuXfDyy5CW5m3r0AEeeaRWDmUtVugq5G/f/s2zP7D5QPo06c/HH0O9etCliw+LExERqYUUJEVEagOXCz76CObONcNai02YALfeWmuHshabt3Mex7KPARAeGM5dfe5ixw7TOTtmDNjtPi5QRESklqnd/7IQEakLTpyAP/3JTKxTLDLSDGXt29d3dVWTpFNJfLL7E8/+7T1vJ8SKZcsWSEiA5s19V5uIiEhtpSApIlKTJSbCG29AXp63rWtXePhhaNDAd3VVE6fbyWvfvIbLMmtjdm7QmavaXMXKlaZjdsAA39YnIiJSWylIiojURDk5JkCuWuVtczjglltg0qQ6M5bz/W3v80P6DwAE2AO4r999pKTY2LfPLJEZFeXjAkVERGopBUkRkZrm++/hz3+GlBRvW5Mm8NvfQvv2vqurmm1M3siCPQs8+z/r9jOaR7Xg/31pJqnt2dOHxYmIiNRyCpIiIjWF0wkffmgm1Sk5oc6oUfDLX0JIiO9qq2apuam8suEVz37vJr2Z0GkCe/dCaiqMHAmBgT4sUEREpJZTkBQRqQmSkuCVV+DgQW9bRATcdx8MGuSzsnzB6Xby0tcvkVWYBUD90Po8dPlDFBXZ+PZbaNwY2rb1cZEiIiK1nIKkiIg/c7thwQL44APTI1msWzd46KE6MaHOmT7Y/gG7U3cDYLfZeWTQI0QFR7F+PeTnw8CBPi5QRESkDlCQFBHxV8nJMGtW6WU9AgPh5z+HcePAZvNdbT6y+dhm5u+e79n/Wbef0blhZzIyYNcu6NixTmZrERGRaqcgKSLibywL/vtfeOcdKCz0trdrZ9aGbNHCZ6X5UlpuGn/Z8BfPfq/GvZjUeRIA69dDQAD06+er6kREROoWBUkREX+SkgKvvgrbt3vbHA64+WazrIfD4bvafMjldvGndX/idMFpAGJDY3no8oew2WwcOABHj5ohrXVoviERERGfUpAUEfEHxb2Q771nHvQrlpBgeiFbt/ZZaf5g7s657Dy5EwAbNn438HdEh0STmwtr10JcHHTu7OMiRURE6hAFSRERXztyBF57DXbv9rbZbKYH8uab6/w6FluOb+GjXR959qd2m0rXuK4ArF5t5iAaPhzsdh8VKCIiUgcpSIqI+IrTaWZknTu39IysLVrAAw9Ahw6+q81PHMw4yMy1M7Ew62b2bNSTG7vcCJg5iA4fNkNa69XzZZUiIiJ1j4KkiIgvHDhgnoU8dMjb5nDAjTfC5Ml1vhcS4ET2CWasnEGeMw+ABmENeHjgw9htdrKyzAQ7TZtCly4+LlRERKQOUpAUEalOBQXw4YemJ9Lt9ra3awf332+eiRROF5zmyZVPkpGfAUB4YDhPDX+KeiH1sCxYudKcN3x4nVwFRURExOcUJEVEqsumTfDmm3DihLctKAh+9jOzLmQdnZH1TAXOAp5e9TTJWckABNoDeXzo47SMbgnAjh1w/DgMGwYREb6sVEREpO5SkBQRqWqpqfD227BuXen2bt3g17+GJk18U5cfcrldvPT1S+xN2wuYGVofvvxhz+Q6GRmwcSPEx+sRUhEREV9SkBQRqSoul1nS49//Lr2kR2Qk3H47jBqlcZklWJbFG5ve4Ntj33raftHrFwxqOQgwI4ETE83jo0OG+KpKERERAQVJEZGqsXcvzJ4NBw+Wbr/iCrjjDoiO9k1dfmzernksP7Dcsz+p0yTGdhjr2f/uO9O5e+WVEBbmiwpFRESkmIKkiEhlysqC99+HZcvAsrztLVrAPfdA166+q82PrTiwgg92fODZH5Ewgtt63ObZT001QbJtW2jd2hcVioiISEkKkiIilcHlMuHx3/+G7Gxve1AQ3Hwz3HADBOiv3PIkHkrk9Y2ve/Z7NurJ/f3vx/a/Yb9FRfDVVxASAoMG+apKERERKUn/qhERuVQ7dsDf/w5JSaXb+/SBu++GRo18UlZNsGjvIt7e8rZnv3W91vxhyB8IsJtfT5ZlnovMzIQxYyA42FeVioiISEkKkiIiF+vkSfjXv2Dt2tLtjRvD//0f9OunyXTOwrIs/rPjP3y460NPW0J0Ak+NeIrQwFBP2+bNJp8PHAjNmvmgUBERESmXgqSIyIUqLIQFC+Djj837YsHBcNNNcP31ZkirlMuyLN7c9CZL9i/xtHVq0Ik/DvsjEUHehSEPHYItW6B9ez1aKiIi4m8UJEVEKsqyYOVKeO89M/tLScOGmSU9GjTwRWU1htPt5JX1r7D68GpPW+8mvZk+eDrBAd5xq+npZkhrXJyW+hAREfFHCpIiIhWxfTv8859ll/No3Rruugs6d/ZNXTVIvjOfmWtnsvn4Zk/b0JZDefDyBz3PRIJZcnP5ctOpO3o0OBy+qFZERETORUFSRORcjhyBOXNg48bS7dHR8LOfmaRjt/umthokuzCbp1c9ze7U3Z62MW3HcHefuz2zswK43fDFF5CbC+PGab1IERERf6UgKSJSnlOn4IMPTNdYyfUgg4Jg/HiYOBFCQ8/+efE4nHmYF9a8wNGso562KV2mcEu3W0qFSID16+HYMRgxAho2rO5KRUREpKIUJEVESsrJgYULzZaf72232WDkSNMLqecgK+zLg1/yxqY3KHAVeNp+0esXjOswrsy5e/bArl3QvTu0a1edVYqIiMiFUpAUEQEoKIDPPoP58yErq/SxHj1g2jTzPKRUSIGzgLc2v8WKgys8bUGOIO7vdz/DEoaVOf+nn8wqKs2bQ//+1VmpiIiIXAwFSRGp25xO+PxzmDfPTBVaUsuWJkD26qX1IC9A8ulkZq6dSVJmkqeteWRzHh38KPH14sucf/IkLFsGkZFwxRX6oxYREakJFCRFpG5yu2HVKvjPf0x3WEmNGsHUqWZJD02kc0FW/7ia1759jXynd1jw8Pjh3NvvXkICQsqcn5pqOoKDg+Haa82riIiI+D8FSRGpW9xuM4byww/NjKwlxcbClCkwahQE6K/HC1HoKuSfW/7Jkv1LPG2B9kDu6n0Xo9uMLjOpDkBamgmRQUFw3XUQEVGdFYuIiMil0L+URKRucLth9WozhPXo0dLHIiPhxhthzBh1iV2Ezcc289bmtziefdzT1iSiCY8OfpTWMeU/V5qebkJkQIAJkZGR1VWtiIiIVAYFSRGp3Vwub4BMTi59LCQEbrjBbOHhvqmvBkvLTePtLW/z9ZGvS7UPbjGYX/f/NWGB5S8CeeqUCZF2uwmRUVHVUa2IiIhUJgVJEamdnE7zDOS8eXD8eOljYWEwdixcf726wi6Cy+1i8Q+L+WDHB6WehQwPDOeOnnecdSgrmBD53/+a99ddB9HR1VGxiIiIVDYFSRGpXQoKzCysCxdCSkrpY+HhMG6c2fRA3kXZfXI3szfOLjUjK8AVra7gjp53EB1y9mR4+rQJkZZlQmS9elVcrIiIiFQZBUkRqR2yssx4yUWLyq4DGRFheh/HjtUQ1ouUkpPChzs/LLUuJECLqBbc0/ceusZ1PefnMzPNj8ftNiEyJqYqqxUREZGqpiApIjXbyZOm93H5ctMbWVJUlAmQ111nhrPKBfsp+yc+3vUxXx76Epfl8rQHO4KZ0nUKN3S8gQD7uX+VJCfDihXmmchrrzWT44qIiEjNpiApIjXToUMmQK5aZSbUKSkuDiZMgCuv1CysF+lY1jE+2vURiUmJuC13qWP9m/Xnl71/SVx43Hmv8/338PXXpgfyqqv0SKqIiEhtoSApIjWHZcG335rhq9u3lz2ekACTJsHgweBwVHt5tcHR00f5aNdHrExaiYVV6liXhl24uevN9Gjc47zXcbth/XrYtQtatoQrroDAwKqqWkRERKqbgqSI+L+8PPjiC1i8uOwMrABdu5oA2asXnGW2UDk7t+Xmu+PfsfzAcjYc3VAmQHaP687N3W4+73OQxQoKzI8rORl69IB+/fRjERERqW0UJEXEf6WkmGk+P/8ccnJKH7PbYdAg8wxkhw6+qa+GO5lzki8OfsGKgys4mXuyzPHLGl/GlK5T6Nywc4WvmZkJy5aZ+Y6GD4f27SuxYBEREfEbCpIi4l/cbtiyBZYsgU2bzHDWksLD4eqrzQQ6DRr4psYazOl2sjF5I8sPLGfL8S1leh8B+jTpw5SuU+jQ4MIC+rFjZlIdm838eBo3rqyqRURExN8oSIqIf8jMNClk2TI4caLs8WbNzPqPI0dCSEj111eDOd1OdqbsZP2R9aw7uo5T+afKnBMVHMUVra5gdJvRNI9qfkHXd7lg82bYts2sDXn11ZpUR0REpLZTkBQR37Es2LPH9D6uXQtOZ9lzLrvMBMjevfWg3QXIK8pj8/HNbDi6gU3HNpFTlFPueT0b9eSqtlcxoPmA8y7jUZ7UVFi5EtLToWNHuPxyTaojIiJSFyhIikj1O30aEhNND+SPP5Y9Hhlplu64+mpo2rT666uBLMviWNYxtp/YzrfJ37L1xFac7nKCORAbGsuo1qMY1XoUjSIaXdT93G7YutWMQg4JMT+qli0v5RuIiIhITaIgKSLVozh5rFgBGzaU3/vYoQNccw0MGQJBQdVfYw1iWRbJWcnsOLGDHSk72Jmyk4z8jLOeHxcWx+UtLmdA8wF0atAJh/3il0fJyDD/HyA1Fdq2NXMeablOERGRukVBUkSqVkqKCY9ffGGSx5mCg2HoUBgzxqQSKVdeUR4HMg5wIP0Ae1L3sPPkznKfdSypVb1WXN7chMeEegnYLnFosGWZ5Ts3bjQ5/8oroXXrS7qkiIiI1FAKkiJS+XJyYN06+Oor2Lmz/HM6dIBRo0zvY1hY9dbn57ILszmYcZD96fs5kH6AAxkHSM5KPu/nwgPD6dKwC90bdWdA8wEXPWy1PMeOmY7k1FRISDA/ttDQSru8iIiI1DAKkiJSOZxO+O47Ex6//RYKC8ueExUFI0bA6NF1/oE6t+XmZM5Jjp4+WmpLzko+5xDVkiKCIujSsAvd4rrRrVE3EuolYLfZK7XOjAz45hs4fBgiIsykueo4FhEREQVJEbl4lgX79pkH5lavNpPonMlmg169TO9j//4QUDf+2rEsi4z8DE7mnCQlJ4UTOSc871NyUjiefZwid1GFr2e32WkZ1ZI2sW1oE9OGrnFdK2W46tnk5pplPPfuNbOw9u8PXbrUmR+fiIiInIf+SSAiF8ay4NAhWLPGbOWt+Qjm4bkRI8zzj7Gx1VtjFbEsiwJXAacLTnO64DQZeRmcyj9Fel46GfkZZORleN6n56VfUFAsKdAeSHx0vCc0to1tS3y9eIIcVT8BUVGRWQ9y+3YzP1LXrmYFFi3dKSIiIiUpSIpIxfz4ozc8HjtW/jn168Pw4SZAxsdXa3kVYVkWha5C8p355DnzyC3KJbcol5zCHPNalOPZzynKIasgi6zCLLIKsjhdeJqsgqyLDoflqRdSj+aRzWke5d2aRTUjLjyu0oeonk9+vlnSc8cOyMuDNm2gb18zGllERETkTAqSIlK+4p7H9evh66/hyJHyzwsPhwEDTHjs1g3s9jMuY+G23LgsFy63q9Sr0+3E5TavZ24uy0WRq4gidxFOt5MiVxGFrkKK3EWe9iJXEQWuAgpdhRS6CilwFnj2i9/nO/M9wbHAWYCFVQ1/eEZkUCQNwxoSFx5XZmsU0YiIoIhqq+VsTp0y4XHfPvOYa/Pm0KcPxMX5ujIRERHxZwqSfmzrT1vZcWJHld6jKv9RbVlVeO1z1H3mfc/3HS/k/JLnlnde8fHiY+Vdu7xrWJZV6nrn2i9+X/JeZ74v7xXMBC/Fwc6zX/Jcl4sGh1OJ332Mlt8fIyIjx1ul5amAwiAHB9o3ZG+nhvzYKogixxZcBzbi3u/G5XZ5gqPbcnvuVVsE2gOJCo4iMiiSmNAYYkJiiA2N9bwv2RYa6L/Tmh49agLkkSPgcEC7dmYYay0ZhSwiIiJVTEHSj+1K2cVH33/k6zKklgtwuok/fJoO+0/RcV8G4bneoZu5Jc4rCrTzQ5t67OpQnwOto3EG/K/nsSgDKm+0Z5ULcgQREhBCiCOE0MBQwgLDCA8MJywwjIigCLMf5N2PCo7yBMfI4EiCHcFVNsFNVSsshAMHzIosGRlm+Y4+faBTJy3lISIiIhdGQVKkDorILqTtoUzaHzhFq6TTBBW5yj2vINjBvtb12NMuhv2toikKclzU/WzYCLAH4LA7cNgcpd4X75e3OezmWJAjiEB7oHl1BBJoD/S8BjmCCA4INq+O4FL7QY4gQgNCTXD83+awX9x3qKmcTrN0x/795tXt9j7K2qaN6Y0UERERuVAKkn6sR+MeBDoCfV3GJbFx9p6bquzVOfO+Z97rXHVdyPklzzvbPYvbyzv3zLazfabk/pnvS55Tsq3kK5ZFyI/JRG7fQ/jW7wk5dARswUAjbNGNvBXYwB0ZSX7fy8jv05PCrp1oFhTMcMzyEw6bA7vNjs1mw26zl9qKj9ltdhx2R5nzpfq43WY+pP37zWOuRUUQFmaW72jTRs8/ioiIyKVTkPRjXeO60jWuq6/LkJoqMxO2boUtW+C778xYxmIh0aXPbdIE+vWDgQOhY0ei7dU7Y6hcusJCEx6PHIGkJDPzalCQWYWlbVto2tQs6SkiIiJSGRQkRWoLp9Os37Bli9kOHDj7uXa76Z7q29cESKWMGseyIC3NTJpz5IhZztPthsBAaNHChMcWLTR0VURERKqGgqRITWVZZm3HbdvMtmOHWQzwbCIjzcwq/fqZFebDw6uvVrlklmWW6jhxAo4fNwEyL88cq18func3wbFRozIrsIiIiIhUOgVJkZrCsszYxe3bvdvp02c/326HDh2gVy+ztW2rhFGDFBRASooJjikpZissNMdCQsx6j8VbWJhvaxUREZG6R0FSxF9Zlul22rXLrNewaxekpp77M3Fx3uDYvbt6HWsAy4KsLEhPL72dOmWO22xmbce2bc2Pt1EjiI4+9zVFREREqpqCpIi/cLnMFJu7dnm3c/U4AkRFmcDYo4d5bdJEzzr6KZfL/DiLt4wMb2h0Or3nRUWZ4NiunQmNDRua5x5FRERE/ImCpIivZGXB3r1mgpzdu+GHH879jCOYMYy+oe2zAAActElEQVRdu3qDY3y8gqOfcLkgJ8e7ZWebwJiZaV5zckqfHxJiAmPHjuY1NhZiYhQaRUREpGZQkBSpDm63WQ3+hx9MaNyzxwxbPZ/ISDO7ateu0LmzWctB03BWq4ICM6lNfr55LbmVDI3l/T+A0FAzDLVZM9PTWHILCan+7yIiIiJSWRQkRSqbZZkZUvbtM8Fx3z6zFMf5ehsBGjQwwbE4PDZvrh7HS1RUZLbCwtLvS24FBeVv+fnm/wGUJyTEdBBHRJjhp+Hh5n14uHdT76KIiIjUVgqSIpfCssx0mgcOeLcffjDDVs/H4TA9jJ06mfGNnTqZIFlLuN0V31wu7+uZ70tuTmfZ906nCYdOZ/nvKyIwEIKDvVu9euY1JMT0KoaGeoNjSIjZNAGuiIiI1GUKkn7uhx/MsLnaxrJ89/nzffasx10uAk8eI/joAUKOHST46AGCkw/gyMspc2p5l3BGxpLfoh258Z3IbdmR/BbtsAKDvPfbU/r+Jes4s60irxV9f6Gb23329yX3q4LdbvK3wwEBAd7XwEAICjJBr3i/+LV4Cwoq/zU4WKFQRERE5EIpSPq5vXvN4uNyac43OvTM44F5p4lMPUREWhKRqYeITE0iIv0wdpe3i8tlg9yzXM8ZHM7puHacbtzebI3aURgR672fG/ix7L3P974ir+drK7kVt9ntZY+Vt515Xsl9u927lTxWsv1sW3E4PNv7gADvuSIiIiLiewqSfu7aa6v+Hr56BM8vHv3LyYEjR8xEOIcPw48/mtf09NLnhQLNznKNyEgzRLVNG7O1batlOERERESkVlOQ9HPqgakElmXWXzh61GxHjnjDY2rqhV2rQQNISDBhsTg8Nmyo0CgiIiIidYqCpNQehYVmttRjx7yh8ehRSE6u2OQ3JQUFmTUaExKgVSvzmpBgeh9FREREROo4BUmpWYrD4vHjJjCW3FJTL3yWl4AAs8hfy5beLT7eDE1Vd7CIiIiISLkUJMW/WBZkZJglNX76qeyWlnZx1w0JMWsyNmtmXotDY5MmZjYXERERERGpMAVJqV4ul5nIJjXV9CympJjtxAk4edK8r+jif2ey2SAuDpo2NVuLFt7wWL++nmMUEREREakkCpJSedxuOHXKhMS0NPN68qR5LX6flnZpiwzabGZymyZNvIGxeGvUyCwMKCIiIiIiVUpBUs7PsiA72/QkFm8ZGea1ODCmpZk2t/vS7xcRYXoWGzf2bk2amKDYsKF5rlFERERERHxG/yKvqywL8vIgM9MEwFOnzFb8vvi1ODQ6nZV373r1TCBs2NAbDhs1MuExLg7CwirvXiIiIiIiUukUJGsLy4KcHLNe4unTJiCWfF+8nTrlfX+xzyKeS1SUWWuxfn2zNWxo9otfGzTQ8FMRERERkRpOQdKfFc9cmpV17u30afNaGcNKzyYsDGJiTDiMiYHYWO9+cXCMjVVIFBERERGpAxQk/dmnn8KiRVV3/aAgM8w0Jqb065ltsbEQHFx1dYiIiIiISI1So4OkzWZrB7wEXA40AjIty6rn26oqUWTkhZ0fFmaGlpbcIiNNIIyONq9RUd79kJCqqVtERERERGq1Kg2SNpvNArAsq9IX8LP9//buPTqPus7j+PtrEwiFQJC2AUpJSgjGiNLVLpeyXL2AF5bLuq7uoi3CYVfXPbirrrqr0h45eM7e1LOKWEGLVIVdOCDsipcDVMQuaNWAEFNiaUpb2rQppDSGQJ/y3T9mnnQyfW7zZJ5Lks/rnDmTzMzzm+/v953f8+SXZy5ms4C7gROBW4EtwFi4bjlwLXCeu69Je99Vc+yxcPLJwV1Mm5vzT9lBo+5mKiIiIiIiVTCVRx4LgW7gG+5+da2DqYizzw4mERERERGROvKqWgcwCceG82drGoWIiIiIiMgMU1cDSTPrMrNVZrbZzF4ys0Ez+66ZvSa2nQM/DX+91sw8nJab2QDBaa0AD0bWeRWrIiIiIiIiMm3VzUDSzC4Efg38FfBL4MvA/cBlwC/M7I2RzVcAt4Q//zT8fQWwBvgS+weZt0TWrahsDepbJpNhaGiITCaTd/327dvZvn07mUxmwva5fh4bG5uwfbycLVu2TFiXb/+ZTIYtW7bw5JNPMjY2VjTWeJz56jk2NnZAGYViKBRzvKxc5eTatlA9xsbGWL9+PSMjI+P1GR4e5pFHHmF4eHhCWdm2jsdXrE1yLS/UBvHl2RizeUmai2LtXqiN05aty/Dw8Hi7x4+7eEwjIyPj9Y/WIdou+fpJ0nYoJfZ8eci3XbHjffv27QXbPUndyo0r37pC/Si+TXSeL6eFXldKX8hXnyQ5L6XdS61rofe1yeSqWB1KWZ60nGqqVAyllFuL+lfyWKiHfE7WdKhDNZT6WV+NOCqZLx0P5amLayTN7Ejge8AocLa790bWvQ54FLgJeCOAuy83s3OBpcAad18eKW6NmbUA5wCrpvTNdlKSyWRYtWoVGzZsoKOjg2XLltEQuTFPJpPh5ptv5u677wbgoosuYtasWQwMDNDe3g4w4eenn36arVu3MjQ0hJlxySWXcOWVVwJw8803c9ddd7Flyxbmz5/PZZddxtKlS1m9evUB+89kMqxcuZIbbriB0dFRlixZwo033shtt92WM9Z4nNn9RtevWrWK/v5+tm3bxjHHHENnZyfLli0DyNkG2TKzMR933HFceuml4zHHy7r88ssPqEu27Oi2J5xwwni7xesxNjbG1VdfzVNPPQVAc3h33t///veMjY1xyCGHcPHFF7Nr1y5aW1vZtm0bO3fuZOvWrePxZeudr02yuYguL5SHeNtkMhmuvvpq+vv76ezsZOXKlTRF7vJbLBelHHuF8hUvZzKy7b1+/Xp27tzJnDlzABgZGWFsbIwlS5Zw00030dTUNB7T+vXrefjhh3F3TjzxRJYsWcLmzZtZsGABa9euHa9Pdnm0n+TrY4X6YLHY8+Uh33Y33HBDzn4UzZu7M2fOHObPn39Au0fjLVa3JPFH44q2ZXRdoX6U7X/ZbVpbWxkcHKS1tZWtW7fy2GOP8eKLL07IabQ+8dfFj7lieYrWJ5r/Yjlvb29n37593HvvvbzyyivMnTv3gHaP7ztfXQu9r+V6f5pMX8rXHkmP53KP/zRVKoZSyq1F/dPeZ1rvCfWiHo7JqaDUz/pqxFHJfOl4KF+9fCP5AaAFuDY6iARw9yeBbwB/ZGbdae/YzK42s3Vmtm7nzp1pF18XhoeH2bBhAwsXLmTDhg0MDw8fsL63d3+z9/T00Nvby8KFC+nt7T3g59bWVvr6+ti7dy8Avb29DA8Pj5ezd+9eRkdHyWQy9Pb2smnTppz7Hx4epqenh9HRUWbPnk1fXx9PPPFE3ljjcWb3G69na2sr/f39tLa2jpeRrw3iMe/du3dCzPGyctUl136j7Ravx6ZNm+jv72fBggUMDAwwNjbGnj172LFjB3PnzmXHjh3s27eP/v5+mpub6evrY3R0dEJ88fjjbZJreaE8xJdnY+zo6KC/v59NmzYVPGbiuSjl2CuUrzRl69La2sqOHTs48sgjGRgY4IUXXhg/7rL1y8bU3NzMM888w4IFC+jr66Onp4eFCxfS09NDX18fHR0dE5YXynexdigl9nx5yLddvn4UzdvevXvp6+vL2e7ReIvVLUn80biibRldV6gfxftlc3Pz+Ly3t5eRkZEDchqtT/x18boXy1O0PtH8F8t5b28vPT09QPAHS652j+87X10Lva/l6+PlKvS+mWQ/5R7/aapUDKWUW4v6p73PtN4T6kU9HJNTQamf9dWIo5L50vFQvnoZSJ4Rzk8Jr3OcMAEnhetfm/aO3X2luy9298Vz585Nu/i60NLSQkdHBxs3bqSjo4OWlpYD1nd37x+jL1q0iO7ubjZu3Eh3d/cBPw8ODtLV1UVjYyMA3d3dtLS0jJfT2NjI7NmzaWhooLu7m7a2tpz7b2lpYdGiRcyePZvR0VG6uro4+eST88YajzO733g9BwcH6ezsZHBwcLyMfG0Qj7mxsXFCzPGyctUl136j7RavR1tbG52dnePfZDU1NdHc3My8efPYuXMn8+bNY9asWXR2drJnzx66urqYPXv2hPji8cfbJNfyQnmIL8/GmP22qK2treAxE89FKcdeoXylKVuXwcFB5s2bx/PPP097ezuHH374+HGXrV82pj179nD88cezefNmurq6WLRoERs3bmTRokV0dXWxYcOGCcsL5btYO5QSe7485NsuXz+K5q2xsZGurq6c7R6Nt1jdksQfjSvaltF1hfpRvF/u2bNnfN7d3c1hhx12QE6j9Ym/Ll73YnmK1iea/2I57+7uZtGiRQA0NDTkbPf4vvPVtdD7Wr4+Xq5C75tJ9lPu8Z+mSsVQSrm1qH/a+0zrPaFe1MMxORWU+llfjTgqmS8dD+Uz98rdg6bU50ia2U+At5RQ5DJ3vyV8zbnAg8CK2KmtZT9HcvHixb5u3bpSN59SMpkMw8PDtLS05Py6PntuODB+6l92+1w/H3bYYeP/sZkzZ86EU+Ky55g3NDSMr8u3/+y597t376ajo2P89MJ8scbjzLU+G9/IyMiEMgrFUCjmeFm5ysm1bbTd4nGOjY2xadMm5s+fz8jICABNTU309fXR1dVFJpMZLyvb1vH4irVJruWF2iC+PBtjW1tbztMpi+WiUNml5CtN2bpkTw+cP38+w8PDE467eExNTU1s3bqVtrY2GhoaxuuQyWTG2yW6HPLnu1g7lBJ7vjzk267Y8Q7Bh2e+do++vljdksQfLTfaltF1hfpRfJvofGhoKGdOo/WJv66UvpCvPtH8F8s5ULTd4/suJeZ8r0mrLyV5zyinnGqqVAyllFuL+lfyWIDy3xPqRT0ck1NBqZ/11YijkvnS8TCRmf3K3RcX3a5OBpJ3AH8GnOLuj5dY9rloICkiIiIiIpKaUgeS9XJq6yPh/KyUytsXzmelVJ6IiIiIiIiE6mUg+S1gmOCZkKfGV5rZq8JvIEu1K5wfn0JsIiIiIiIiElGVk4DNbFWB1R92911m9m7gLuARM7sfeBJ4hWAweAZwFJD/AqGJHgxf+wUzOxl4HsDdryuvBiIiIiIiIpJVratJlxZY91Fg1N3vN7M3AB8HLiA4zfVl4FngAeDOUnfm7r8zs6VhWR9m/wBUA0kREREREZFJquhAsthNdnJsPwB8pMRt1wB5y3f31cDqJPsXERERERGR4urlGkkRERERERGZIjSQFBERERERkUQ0kBQREREREZFENJAUERERERGRRDSQFBERERERkUQ0kBQREREREZFENJAUERERERGRRDSQFBERERERkUQ0kBQREREREZFENJAUERERERGRRDSQFBERERERkUQ0kBQREREREZFEzN1rHUPdMLOdwKZax1Ehc4ChWgchFaUcT3/K8fSnHM8MyvP0pxxPf9M5x23uPrfYRhpIzhBmts7dF9c6Dqkc5Xj6U46nP+V4ZlCepz/lePpTjnVqq4iIiIiIiCSkgaSIiIiIiIgkooHkzLGy1gFIxSnH059yPP0pxzOD8jz9KcfT34zPsa6RFBERERERkUT0jaSIiIiIiIgkooGkiIiIiIiIJKKBpIiIiIiIiCSigeQ0YmaNZnaNmX3LzHrM7GUzczO7qoyy2sPX5ptuq0QdpLA0cxwpc4mZ/cDMnjOzUTN73Mw+amaz0oxdkkkjL+rHtWdmx5nZN83sWTN7ycwGzOxLZnZkLcqR9KWRm/A1+frp9krGL4WZ2bvN7D/N7Gdm9kKYk9VllqV+XIfSyvFM7McNtQ5AUnUo8KXw50FgO7BgkmU+BtydY/kTkyxXypNqjs3sYuBOYAy4HXgOuAj4InAm8OeTCVbKU4G8qB/XgJl1AGuBecD3gT7gVOAa4EIzO9Pdd1WrHElfyrnZzf7396iRNGKVsn0GOIUgD1uArnIKUT+ua6nkODSz+rG7a5omE3AQ8HbgmPD35YADV5VRVnv42lW1rpemiuX4cGAH8BKwOLK8ieDDzoH31rrOM21KMy/qxzXP5Y/C9v+72PL/CJffWM1yNNV1jgeAgVrXR1PO3JwHdAIGnBvmdXWtjhVNdZ3jGdePdWrrNOLuL7v7fe6+rdaxSGWknON3A3OB29x9XWQfYwT/nQP4UAr7kWSUl2nAzE4A3kbwh8VXY6uvBf4AvN/MDq1GOZI+5WZmcPcH3b3fw5FCOXSs1Lc0cjxT6dRWKeZYM/tr4ChgF/B/7v54jWOSdJwfzn+YY91DwCiwxMwOdveXqhfWjFeJvKgfV182jz9291eiK9x9j5n9nOAPy9OB+6tQjqQv7dwcbGaXA8cTDCweBx5y930pxiy1oX48c8yofqyBpBTz1nAaZ2ZrgKXu/kxNIpK0vCacPxVf4e4ZM9sIvA44AfhdNQOb4SqRF/Xj6subx1A/wR+OJ1H4D8e0ypH0pZ2bo4FbY8s2mtkV7v7T8kKUOqF+PHPMqH6sU1sln1Hg88CbgCPD6RzgQYLzx+/XKRhT3hHhfHee9dnlLVWIRfZLMy/qx7WTVh7VT+tXmrn5FvBmgj9CDwVeD3yd4Drn+8zslPLDlDqgfjwzzLh+rIFknSly6+BcU1m3oC7G3Xe4++fc/dfuPhxODxH8x+xR4ESg7EdOzGT1kuNSQg3numYgoQrnuOS8qB/XtbT6l/pp/UrSV1e4+wPuPujuo+7+hLv/DcGNWA4huLGaTF/qx9PATOzHOrW1/mwguOV/qZ6tVCC5hKfW3QScBpwNfLma+58m6iXH2f+AHpFn/eGx7aR0k8lxxfOiflwVaeVR/bR+VSM3NwIfI+inMnWpH89s07YfayBZZ9z9zbWOoQQ7w7lOiStDHeV4PbCY4JqMX0VXmFkDsBDIAE9XP7SpbZI5rlZe1I8ra304PynP+s5wnu+aqbTLkfRVIzc7wrn66dSmfjyzTdt+rFNbpRynh3MNMKa2B8L5hTnWnQ3MBtbqjq1VV628qB9X1oPh/G1mNuGz1syagTOBF4FHqlSOpK8auTkjnKufTm3qxzPbtO3HGkjOcGZ2hJl1mdkxseWnmdlBObY/H/j78NdaXbsnCeTLMXAHMAS818wWR7ZvAq4Lf/1alcKU/RLnRf24/rj7BuDHBDdZ+NvY6hUE/5n+trv/AcDMGsMcdkymHKmetHJsZq8zs1fHyzezNuAr4a/qp1OA+vH0p348kenZm9OLmX0K6Ap/XQScAqwluLU0wMPuflNk+2UEd5m6xd2XRZavIXjEwBpgS7j4Dex/FtJn3T37R61UUVo5DtddQjBwGQNuA54D/pTgVuV3AO/RA3qrL2le1I/rU/iHxlpgHvB9gse1nAacR3AK2xJ33xVu2w5sBDa5e3u55Uh1pZFjM1sOfIrgW6uNwB6gA3gn0AT8ALjU3V+uQpUkJnw/viT89WjgAoJvln4WLhty94+H27ajfjzlpJHjGduP3V3TNJoI/mD0AtOq2PbL8iy/EvgfYAAYAV4CngFuB86qdT1n8pRWjiPrzyR4g3ue4NSa3xJ8WzWr1nWdyVOSvKgf1+8ELCAY5G8DXgY2Edzc6NWx7drDHA5MphxNUy/HBI/k+R7QBwwDewmuYf4J8AHCf/prqll+lxf5zB2IbKt+PAWnNHI8U/uxvpEUERERERGRRHSNpIiIiIiIiCSigaSIiIiIiIgkooGkiIiIiIiIJKKBpIiIiIiIiCSigaSIiIiIiIgkooGkiIiIiIiIJKKBpIiIiIiIiCSigaSIiEx7ZtZuZm5mq2odSyXVez3N7BAz+5yZ9ZnZmJltNrPrzayx1rGJiEgyGkiKiIhUSCUGdvU+WMzHzI4Bfgl8BngM+DLwAvBp4Cs1DE1ERMrQUOsAREREqmAr8Fpgd60DqbC6rKeZHQTcC7QD57n7z8PlnweeBK4ys2vdfXvtohQRkST0jaSIiEx77r7X3fvcfVutY6mkOq7nx4E3AZ/MDiIB3H0EuIvg75GzahSbiIiUQQNJERGpW2b2HjN7yMx2m9mLZvZbM/u0mR0c2278dE8zO8nMbjezHWb2ipmdW+x0UDM7zczuMLPtZvZyeO3e183s2AL7aTez28xsKLzeb52ZvSuy7XJgY/jr0vB12WlZZLtlZnanmT0d1vEFM/u5mV2eI86CZZZQz3Las2A9izGzQ4BPANuAlTk22RXOjy61TBERqT2d2ioiInXJzK4nuH5uCPguMAK8HbgeuMDM3urue2Mv6wAeBZ4CvgMcQnAdXqH9XAF8A3gJuAfYDHQCVwEXmdnp7v5M7GVtwC+Ap4FbgVcDfwF838ze4u4PAmuAFuAagmsC7468vify89eAXuAhgsHWUcA7gFvN7DXu/tnItqWWmaue5bRnKfUs5tIw5ptzlA/QFM5fLqEsERGpE+butY5BRERkAjM7A1hLMKg7NXvtnJk1EJwK+S7gn939+nB5O/u/qfuCu/9TrLzs+lvcfVlk+UnAE8AzwDnuvjWy7nzgJ8A97n5pjv0sd/cVke0vAH4I3Ofu7yi031hsHe6+IbbsIOA+4GygPRZX3jIL1HMy7Vm0noWY2XeAvwRuA9bn2OTtwKnAO939B8XKExGR+qBvJEVEpB59MJxfF70Bi7tnzOxjBN/YXUXwbVrUILCC0n0IaASuiQ7Wwn09YGb3EHwr2ezueyKrNwHXxbb/kZk9QzAoKll8EBkue9nMvgqcD7wZ+HaSMnMotz3TqOefhPP3Ftmut8TyRESkDmggKSIi9eiN4fyB+Ap3f8rMtgALzazF3Ycjqx9z95cS7OeMcH6Omf1xjvXzgFnAScCvIst73H1fju03R8osiZkdD3ySYMB4PMHpuFHzk5SXR7ntOal6mtmhBHV6wt1fn2P9YcBzwKC7DxSvhoiI1AsNJEVEpB4dEc7z3X10G8EA5QggOvBJ+viIo8L5J4psd1js9+GcW0GGBDeyM7MTCK5BPBL4GfBjgkd37CN4VMZS4OB8r0+g3PacbD2zg+Bn86y/gOAb4f8toSwREakjGkiKiEg9yj4H8WjggFM/gWNi22UlvfA/+/oj3L3gTXkq5B8IBrNXuPuq6Aozex/BQDIN5bbnZB0UzvN9S3xFOP9myvsVEZEK0+M/RESkHv0mnJ8bX2FmJwLHARtjp2GW45FwXqlnGGZPC52VZ/2J4fzOHOvOKbPMXKrVnnHZb4gPeLSHmZ1OcG3mfe7+i5T3KyIiFaaBpIiI1KPsN1SfMbO52YVmNgv4N4LPr5tT2M9XgL3AF8M7uE5gZgeZ2WQGmc8TfEt6fJ71A+H83Nh+LyC4+U05ZeZSrfacwN2HgN8BbzKzN0T220ZwF9fdwIfT3q+IiFSeTm0VEZG64+5rzexfgH8EnjCzO4A/EDwq4mTgYeBfU9hPn5l9kGCg9aSZ/ZDgGZSNBAO1s4CdQFeZ5Y+Y2aPAWeFjMJ4i+EbxHnd/HLiB4PTO/zazO4GtBPW7EPgvgmc2llwmeZ6ZWa32zOM6gmd63m9mq4FDgfcQDIbfqZvsiIhMTRpIiohIXXL3T5rZb4CPAB8gGNxtAD4D/Lu7p/IAe3dfbWaPAR8DzgPeRjDIeha4A7h9krt4P/BFgsHh+wADtgCPu/vjZnYewWDrHQSfy48BlxHc6OaAgWSRMtfkC6Ja7Zljv981s0aCQeyHgCGCQfKK+CNXRERk6jD3pPclEBERERERkZlM10iKiIiIiIhIIhpIioiIiIiISCIaSIqIiIiIiEgiGkiKiIiIiIhIIhpIioiIiIiISCIaSIqIiIiIiEgiGkiKiIiIiIhIIhpIioiIiIiISCIaSIqIiIiIiEgi/w/yb3xwKe2Z0wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 1080x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(15, 8))\n",
    "ax.scatter(theta, y, s=6, alpha=0.4, color=\"k\", label=\"data points\")\n",
    "# ax.scatter(theta, p, s=6, alpha=.4, color = 'b', label='hidden proba')\n",
    "x_values = np.linspace(-theta_std, theta_std, 100)[:, None]\n",
    "y_values_p = psychometric_function(x_values, p0, theta0, wt)\n",
    "ax.plot(x_values, y_values_p, alpha=0.4, color=\"b\", label=\"hidden proba\")\n",
    "y_values = logistic_model(torch.Tensor(x_values)).detach().numpy()\n",
    "ax.plot(x_values, y_values, \"g\", alpha=0.7, lw=3, label=\"torch\")\n",
    "y_values_sk = logistic_model_sk.predict_proba(x_values)[:, 1]\n",
    "ax.plot(x_values, y_values_sk, \"r\", alpha=0.7, lw=3, label=\"sklearn\")\n",
    "ax.set_xlabel(r\"orientation $\\theta$\", fontsize=20)\n",
    "ax.set_yticks([0.0, 1.0])\n",
    "ax.set_yticklabels([\"Left\", \"Right\"], fontsize=20)\n",
    "plt.legend(fontsize=20, frameon=False, scatterpoints=6);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a clear discrepency between the classical logistic function obtained by logistic regression (here, the implementation by `sklearn`) and that obtained by our more detailed model. In particular, the slope is more sharp, a feature which may be important for cognitive processes. But what is the origin of this discrepancy? Is it  the numerical optimization method? Is it the generative model?\n",
    "\n",
    "This are the question we try to resolve here. First, let's retrieve a measure for how well the extracted psychometric curve represent the data: the *losses*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta, p, y = get_data(N=N_test, seed=seed + N_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss = 0.297\n"
     ]
    }
   ],
   "source": [
    "logistic_model, loss = fit_data(theta, y, verbose=False)\n",
    "print(f\"Training loss = {loss:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training sklearn loss = 0.330\n"
     ]
    }
   ],
   "source": [
    "logistic_model_sk, loss_sk = fit_data_sklearn(theta, y, verbose=False)\n",
    "print(f\"Training sklearn loss = {loss_sk:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The units for these losses are *bits*. Indeed, they represent some value of information about the binary data \"$d$\" and the continuous psychometric curve \"$p$\". This information is equal to $\\log_2(p)$ if $d=1$ and $\\log_2(1-p)$ if $d=0$. Putting things together, we obtain the [Binary Cross Entropy](https://pytorch.org/docs/stable/nn.html#bceloss) and if we index datapoints by $k$:\n",
    "\n",
    "$$\n",
    "\\mathcal{L} = \\sum_k d_k \\cdot \\log_2(p_k) + (1-d_k) \\cdot \\log_2(1-p_k)\n",
    "$$\n",
    "\n",
    "You can see that this measure is a form of [Cross_entropy](https://en.wikipedia.org/wiki/Cross_entropy), adapted to binary datapoints."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The losses which were computed above are those obtained during training. Relying on this value may be a dangerous strategy as the model may be overfitting the data. We should therefore measure how the model would generalize with novel data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While it hard to do with real (experimental) data which are often scarse, here we synthesized the data and we can thus compute a testing loss by drawing again a set of new data and computing the loss on that data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing loss = 0.297\n"
     ]
    }
   ],
   "source": [
    "def loss_torch(logistic_model, theta, p, y):\n",
    "    labels = torch.Tensor(y[:, None])\n",
    "    Theta = torch.Tensor(theta[:, None])\n",
    "    P = torch.Tensor(p[:, None])\n",
    "\n",
    "    outputs = logistic_model(Theta)\n",
    "    return criterion(outputs, labels).item() / len(theta)\n",
    "\n",
    "\n",
    "print(f\"Testing loss = {loss_torch(logistic_model, theta, p, y):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing sklearn loss = 0.330\n"
     ]
    }
   ],
   "source": [
    "def loss_sklearn(logistic_model, theta, p, y):\n",
    "    outputs = logistic_model.predict_proba(theta[:, None])[:, 1]\n",
    "    outputs_, labels = torch.Tensor(outputs[:, None]), torch.Tensor(y[:, None])\n",
    "    return criterion(outputs_, labels).item() / len(theta)\n",
    "\n",
    "\n",
    "print(f\"Testing sklearn loss = {loss_sklearn(logistic_model_sk, theta, p, y):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, as we synthesized the data, we can compute the loss on that data with the \"true\" psychometric curve, giving to us the baseline number one can achieve:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing true loss = 0.298\n"
     ]
    }
   ],
   "source": [
    "def loss_true(theta, p, y):\n",
    "    labels = torch.Tensor(y[:, None])\n",
    "    P = torch.Tensor(p[:, None])\n",
    "    return criterion(P, labels).item() / len(theta)\n",
    "\n",
    "\n",
    "print(f\"Testing true loss = {loss_true(theta, p, y):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We are now equipped to make quantitative comparisons. Let's first explore the parameters of the methods.\n",
    "\n",
    "## quantitative comparison of methods : varrying methods' parameters\n",
    "\n",
    "Let's study the influence of each method's meta-parameter, such as the number of iterations. As I learn to use [python decorators](https://realpython.com/primer-on-python-decorators/#a-few-real-world-examples), I will use plenty of them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "import time\n",
    "\n",
    "def timer(func):\n",
    "    \"\"\"Print the runtime of the decorated function\"\"\"\n",
    "    @functools.wraps(func)\n",
    "    def wrapper_timer(*args, **kwargs):\n",
    "        start_time = time.perf_counter()    # 1\n",
    "        results = func(*args, **kwargs)\n",
    "        end_time = time.perf_counter()      # 2\n",
    "        run_time = end_time - start_time    # 3\n",
    "        print(f\"Finished {func.__name__!r} in {run_time:.4f} secs\")\n",
    "        return results\n",
    "    return wrapper_timer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### influence of learning rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_dict = dict(learning_rate=learning_rate,\n",
    "                    batch_size=batch_size,  # gamma=gamma,\n",
    "                    num_epochs=num_epochs,\n",
    "                    betas=betas,\n",
    "                   N=N, p0=p0, theta0=theta0, wt=wt, theta_std=theta_std, seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "@timer\n",
    "def explore_param(default_dict, variable, var_range, do_fit=True, do_SKL=True):\n",
    "    results = np.zeros((4, len(var_range), N_cv))\n",
    "    timings = []\n",
    "\n",
    "    for i_var, var_ in enumerate(var_range):\n",
    "        kwarg = default_dict.copy()\n",
    "        kwarg[variable] = var_\n",
    "        kwarg['verbose'] = False\n",
    "\n",
    "        for i_CV in range(N_cv):\n",
    "            \n",
    "            kwarg.update(seed=seed + i_CV)\n",
    "            theta, p, y = get_data(**kwarg)\n",
    "\n",
    "            tic = time.time()\n",
    "            if do_fit: logistic_model, loss = fit_data(theta, y, **kwarg)\n",
    "            if do_SKL: logistic_model_sk, loss_SKL = fit_data_sklearn(theta, y, **kwarg)\n",
    "            toc = time.time()\n",
    "\n",
    "            if N_test > 0:\n",
    "                kwarg.update(N=N_test, seed=seed + i_CV + N_test)\n",
    "                theta, p, y = get_data(**kwarg)\n",
    "                if do_fit: loss = loss_torch(logistic_model, theta, p, y)\n",
    "                if do_SKL: loss_SKL = loss_sklearn(logistic_model_sk, theta, p, y)\n",
    "\n",
    "            results[0, i_var, i_CV] = loss_true(theta, p, y)\n",
    "            if do_fit: results[1, i_var, i_CV] = loss\n",
    "            if do_SKL: results[2, i_var, i_CV] = loss_SKL\n",
    "            results[3, i_var, i_CV] = toc-tic\n",
    "            \n",
    "        print(f\"{variable}: {var_:.5f}, Loss: {np.mean(results[1, i_var, :]):.5f}, loss_P: {np.mean(results[0, i_var, :]):.5f}\")\n",
    "\n",
    "    return results\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning_rate: 0.00005, Loss: 0.29199, loss_P: 0.29061\n"
     ]
    }
   ],
   "source": [
    "learning_rates = learning_rate * np.logspace(-2, 1, N_scan, base=10)\n",
    "results = explore_param(default_dict, variable='learning_rate', var_range=learning_rates, do_SKL=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_explore_param(variable, var_range, results):\n",
    "    opts_scat = dict(marker=\".\", lw=0, alpha=3 / N_cv, ms=20)\n",
    "    opts_line = dict(lw=1, alpha=1)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(15, 8))\n",
    "    if results[1, ...].sum()>0: ax.plot(var_range, results[1, :, :]/results[0, :, :], **opts_scat, color=\"green\")\n",
    "    ax.plot(var_range, results[0, :, :]/results[0, :, :], **opts_scat, color=\"blue\")\n",
    "    if results[2, ...].sum()>0: ax.plot(ar_range, results[2, :, :]/results[0, :, :], **opts_scat, color=\"red\")\n",
    "\n",
    "    if results[1, ...].sum()>0: ax.plot(var_range, np.mean(results[1, :, :]/results[0, :, :], axis=-1), **opts_line, color=\"green\", label=\"loss\")\n",
    "    ax.plot(var_range, np.mean(results[0, :, :]/results[0, :, :], axis=-1), **opts_line, color=\"blue\", label=\"true\")\n",
    "    if results[2, ...].sum()>0: ax.plot(var_range, np.mean(results[1, :, :]/results[0, :, :], axis=-1), **opts_line, color=\"red\", label=\"loss_SKL\")\n",
    "\n",
    "    # ax.set_xlim(np.min(learning_rates_), np.max(learning_rates_))\n",
    "\n",
    "    ax.set_xlabel(variable)\n",
    "    ax.set_ylabel(\"Loss\")\n",
    "    ax.set_xscale(\"log\")\n",
    "    ax.legend(loc=\"best\")\n",
    "    return fig, ax\n",
    "\n",
    "fig, ax = plot_explore_param(variable='learning_rate', var_range=learning_rates, results=results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are at a sweet spot with our learning rate, still it is valid on a wide range. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### influence du nombre d'epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochss = num_epochs * np.logspace(-2, 1, N_scan, base=10)\n",
    "num_epochss = [int(num_epochs_) for num_epochs_ in num_epochss]\n",
    "\n",
    "results = explore_param(default_dict, variable='num_epochs', var_range=num_epochss, do_SKL=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plot_explore_param(variable='num_epochs', var_range=num_epochss, results=results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, we are at a sweet spot with our number of epochs, and this is true for both methods. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### influence of minibatch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_sizes = N * np.logspace(-3, 0, N_scan, base=2)\n",
    "batch_sizes = [int(batch_size_) for batch_size_ in batch_sizes]\n",
    "\n",
    "results = explore_param(default_dict, variable='batch_size', var_range=batch_sizes, do_SKL=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plot_explore_param(variable='batch_size', var_range=batch_sizes, results=results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, `batch_size` as minor effects on the cost, but it can on the CPU time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15, 8))\n",
    "ax.plot(batch_sizes, np.mean(results[3, :, :], axis=-1), **opts_scat)\n",
    "ax.set_xlabel(\"batch_size\")\n",
    "ax.set_ylabel(\"CPU time (s)\")\n",
    "ax.set_ylim(0)\n",
    "ax.set_xscale(\"log\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### influence of `beta1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta1s = 1.0 - np.logspace(-3, -2, N_scan, base=10, endpoint=True)\n",
    "results = explore_param(default_dict, variable='beta1', var_range=beta1s, do_SKL=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plot_explore_param(variable='beta1', var_range=beta1s, results=results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The influence of this parameter is limited, such that using `Adam` is perhaps overkill. A simple `SGD` should be tested. Similarly, for `beta2`:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### influence of `beta2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta2s = 1.0 - np.logspace(-7, -2, N_scan, base=10, endpoint=True)\n",
    "results = explore_param(default_dict, variable='beta2', var_range=beta2s, do_SKL=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plot_explore_param(variable='beta2', var_range=beta2s, results=results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### influence of `C`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cs = C * np.logspace(-2, 2, N_scan, base=4)\n",
    "results = explore_param(default_dict, variable='C', var_range=Cs, do_fit=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plot_explore_param(variable='C', var_range=Cs, results=results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### influence of `tol`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tols = tol * np.logspace(-2, 2, N_scan, base=10)\n",
    "results = explore_param(default_dict, variable='tol', var_range=tols, do_fit=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plot_explore_param(variable='tol', var_range=tols, results=results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## quantitative comparison of methods : varrying experimental parameters\n",
    "\n",
    "Now that we now more about methodological parameters, let's study more crucial parameters like that of the experiment.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### influence of number of trials\n",
    "\n",
    "The number of trials is crucial as if defines the number of our datapoints, and also the length of the experiment. This is important as we want to make this number as low as possible. Indeed, observers doing the experiment, for example a master student in front of the computer screen, may experience fatigue which would prevent accurate recordings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ns = np.logspace(1.5, 3, N_scan, base=10, endpoint=True)\n",
    "Ns = [int(Ns_) for Ns_ in Ns]\n",
    "\n",
    "results = explore_param(default_dict, variable='N', var_range=Ns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plot_explore_param(variable='N', var_range=Ns, results=results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a consequence, $20$ trials is not enough and $100$ is OK. This depends on our expectations on the the retrieved data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### influence of theta_std\n",
    "\n",
    "The convergence of the fitting procedure may also depend on the parametrers of the data which were set to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    f\"p0 = {p0:.3f}, theta0 = {theta0:.3f}, wt = {wt:.3f}, theta_std = {theta_std:.3f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of this is `theta_std` and is describing the \"width\" of tested orientation values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_stds = theta_std * np.logspace(-1, 1, N_scan, base=2, endpoint=True)\n",
    "\n",
    "results = explore_param(default_dict, variable='theta_std', var_range=theta_stds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plot_explore_param(variable='theta_std', var_range=theta_stds, results=results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The value of  `theta_std` as a clear influence on the loss in particular for classical logistic regression (`sklearn`) which will have a problem with datapoints caused by the lapse rate `p0`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### influence of `p0`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p0s = np.logspace(-3, -0.7, N_scan, base=10, endpoint=True)\n",
    "\n",
    "results = explore_param(default_dict, variable='p0', var_range=p0s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plot_explore_param(variable='p0', var_range=p0s, results=results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, the lapse rate `p0`as an influence on the cost: when low ($p0<0.01$), cost are similar. When higher, the two methods diverge and our method is obviously better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After this quantitative comparison of the methods, let's now study how the methods compare when retrieving the parameters.\n",
    "\n",
    "## comparing the predicted values\n",
    "\n",
    "In this section, we will change one parameter after antoher, while keeping the others fixed and check the retrieved value obtained by both methods.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    f\"p0 = {p0:.3f}, theta0 = {theta0:.3f}, wt = {wt:.3f}, theta_std = {theta_std:.3f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### changing `p0`\n",
    "\n",
    "Let's start by changing the lapse rate `p0`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_scan = 20\n",
    "p0s = np.logspace(-3, -0.7, N_scan, base=10, endpoint=True)\n",
    "\n",
    "p0s_, wts_, theta0s_, p0_tos, theta0_tos, theta0_sks, wt_tos, wt_sks = (\n",
    "    [],\n",
    "    [],\n",
    "    [],\n",
    "    [],\n",
    "    [],\n",
    "    [],\n",
    "    [],\n",
    "    [],\n",
    ")\n",
    "\n",
    "for p0_ in p0s:\n",
    "    for i_CV in range(N_cv):\n",
    "        theta, p, y = get_data(p0=p0_, seed=seed + i_CV)\n",
    "\n",
    "        logistic_model, loss = fit_data(theta, y, verbose=False)\n",
    "        logistic_model_sk, loss_SKL = fit_data_sklearn(theta, y, verbose=False)\n",
    "\n",
    "        theta0_to, wt_to, p0_to = get_params(logistic_model, verbose=False)\n",
    "        theta0_sk, wt_sk = get_params_sk(logistic_model_sk, verbose=False)\n",
    "\n",
    "        p0s_.append(p0_)\n",
    "        theta0s_.append(theta0)\n",
    "        wts_.append(wt)\n",
    "        p0_tos.append(p0_to)\n",
    "        theta0_tos.append(theta0_to)\n",
    "        theta0_sks.append(theta0_sk)\n",
    "        wt_tos.append(wt_to)\n",
    "        wt_sks.append(wt_sk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(15, 8))\n",
    "\n",
    "axs[0].scatter(p0s_, p0_tos, label=\"torch\")\n",
    "axs[0].plot([min(p0s_), max(p0s_)], [min(p0_tos), max(p0_tos)], \"--\")\n",
    "axs[0].set(xlabel=\"p0 (true)\", ylabel=\"p0 (predicted)\")\n",
    "axs[0].legend(loc=\"upper left\")\n",
    "\n",
    "axs[1].scatter(p0s_, theta0_tos, label=\"torch\")\n",
    "axs[1].scatter(p0s_, theta0_sks, label=\"sklearn\")\n",
    "axs[1].plot([min(p0s_), max(p0s_)], [theta0, theta0], \"--\")\n",
    "axs[1].set(xlabel=\"p0\", ylabel=\"theta0 (predicted)\")\n",
    "axs[1].legend(loc=\"upper left\")\n",
    "\n",
    "axs[2].scatter(p0s_, wt_tos, label=\"torch\")\n",
    "axs[2].scatter(p0s_, wt_sks, label=\"sklearn\")\n",
    "axs[2].plot([min(p0s_), max(p0s_)], [wt, wt], \"--\")\n",
    "axs[2].set(xlabel=\"p0\", ylabel=\"slope (predicted)\")\n",
    "axs[2].legend(loc=\"upper left\")\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our method is able to fairly accurately retrieve the value of the lapse rate. The errors obtained in the fitting of the other parameters are comparable forr `theta0`but are high on the slope. The slope is clearly overestimated depending on the lapse rate. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### changing `theta0`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_scan = 20\n",
    "theta0s = .61803 * theta_std * np.linspace(-1, 1, N_scan, endpoint=True)\n",
    "\n",
    "p0s_, wts_, theta0s_, p0_tos, theta0_tos, theta0_sks, wt_tos, wt_sks = (\n",
    "    [],\n",
    "    [],\n",
    "    [],\n",
    "    [],\n",
    "    [],\n",
    "    [],\n",
    "    [],\n",
    "    [],\n",
    ")\n",
    "\n",
    "for theta0_ in theta0s:\n",
    "    for i_CV in range(N_cv):\n",
    "        theta, p, y = get_data(theta0=theta0_, seed=seed + i_CV)\n",
    "\n",
    "        logistic_model, loss = fit_data(theta, y, verbose=False)\n",
    "        logistic_model_sk, loss_SKL = fit_data_sklearn(theta, y, verbose=False)\n",
    "\n",
    "        theta0_to, wt_to, p0_to = get_params(logistic_model, verbose=False)\n",
    "        theta0_sk, wt_sk = get_params_sk(logistic_model_sk, verbose=False)\n",
    "\n",
    "        p0s_.append(p0)\n",
    "        theta0s_.append(theta0_)\n",
    "        wts_.append(wt)\n",
    "        p0_tos.append(p0_to)\n",
    "        theta0_tos.append(theta0_to)\n",
    "        theta0_sks.append(theta0_sk)\n",
    "        wt_tos.append(wt_to)\n",
    "        wt_sks.append(wt_sk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(15, 8))\n",
    "\n",
    "axs[0].scatter(theta0s_, p0_tos, label=\"torch\")\n",
    "axs[0].plot([min(theta0s_), max(theta0s_)], [p0, p0], \"--\")\n",
    "axs[0].set(xlabel=\"theta0 (true)\", ylabel=\"p0 (predicted)\")\n",
    "axs[0].legend(loc=\"upper left\")\n",
    "\n",
    "axs[1].scatter(theta0s_, theta0_tos, label=\"torch\")\n",
    "axs[1].scatter(theta0s_, theta0_sks, label=\"sklearn\")\n",
    "axs[1].plot([min(theta0s_), max(theta0s_)], [min(theta0s_), max(theta0s_)], \"--\")\n",
    "axs[1].set(xlabel=\"theta0 (true)\", ylabel=\"theta0 (predicted)\")\n",
    "axs[1].legend(loc=\"upper left\")\n",
    "\n",
    "axs[2].scatter(theta0s_, wt_tos, label=\"torch\")\n",
    "axs[2].scatter(theta0s_, wt_sks, label=\"sklearn\")\n",
    "axs[2].plot([min(theta0s_), max(theta0s_)], [wt, wt], \"--\")\n",
    "axs[2].set(xlabel=\"theta0 (true)\", ylabel=\"slope (predicted)\")\n",
    "axs[2].legend(loc=\"upper left\")\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### changing `wt`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_scan = 20\n",
    "wts = wt * np.logspace(-1, 1, N_scan, base=4, endpoint=True)\n",
    "\n",
    "p0s_, wts_, theta0s_, p0_tos, theta0_tos, theta0_sks, wt_tos, wt_sks = (\n",
    "    [],\n",
    "    [],\n",
    "    [],\n",
    "    [],\n",
    "    [],\n",
    "    [],\n",
    "    [],\n",
    "    [],\n",
    ")\n",
    "\n",
    "for wt_ in wts:\n",
    "    for i_CV in range(N_cv):\n",
    "        theta, p, y = get_data(wt=wt_, seed=seed + i_CV)\n",
    "\n",
    "        logistic_model, loss = fit_data(theta, y, verbose=False)\n",
    "        logistic_model_sk, loss_SKL = fit_data_sklearn(theta, y, verbose=False)\n",
    "\n",
    "        theta0_to, wt_to, p0_to = get_params(logistic_model, verbose=False)\n",
    "        theta0_sk, wt_sk = get_params_sk(logistic_model_sk, verbose=False)\n",
    "\n",
    "        p0s_.append(p0)\n",
    "        theta0s_.append(theta0)\n",
    "        wts_.append(wt_)\n",
    "        p0_tos.append(p0_to)\n",
    "        theta0_tos.append(theta0_to)\n",
    "        theta0_sks.append(theta0_sk)\n",
    "        wt_tos.append(wt_to)\n",
    "        wt_sks.append(wt_sk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(15, 8))\n",
    "\n",
    "axs[0].scatter(wts_, p0_tos, label=\"torch\")\n",
    "axs[0].plot([min(wts_), max(wts_)], [p0, p0], \"--\")\n",
    "\n",
    "axs[0].set(xlabel=\"slope (true)\", ylabel=\"p0 (predicted)\")\n",
    "axs[0].legend(loc=\"upper left\")\n",
    "\n",
    "axs[1].scatter(wts_, theta0_tos, label=\"torch\")\n",
    "axs[1].scatter(wts_, theta0_sks, label=\"sklearn\")\n",
    "axs[1].plot([min(wts_), max(wts_)], [theta0, theta0], \"--\")\n",
    "axs[1].set(xlabel=\"slope (true)\", ylabel=\"theta0 (predicted)\")\n",
    "axs[1].legend(loc=\"upper left\")\n",
    "\n",
    "axs[2].scatter(wts_, wt_tos, label=\"torch\")\n",
    "axs[2].scatter(wts_, wt_sks, label=\"sklearn\")\n",
    "axs[2].plot([min(wts_), max(wts_)], [min(wts_), max(wts_)], \"--\")\n",
    "axs[2].set(xlabel=\"slope (true)\", ylabel=\"slope (predicted)\")\n",
    "axs[2].legend(loc=\"upper left\")\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our method is able to fairly accurately retrieve the value of the lapse rate, but the precision decreases with the lapse rate. The errors obtained in the fitting of the other parameters are comparable forr `theta0` but are high on the slope. The slope is clearly overestimated in the case of the classical logistic regression. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### changing `wt` with a null lapse rate (`p0=0`)\n",
    "\n",
    "Let's decompose the effect of using `torch` to using `sklearn`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_scan = 20\n",
    "wts = wt * np.logspace(-1, 1, N_scan, base=4, endpoint=True)\n",
    "\n",
    "p0s_, wts_, theta0s_, p0_tos, theta0_tos, theta0_sks, wt_tos, wt_sks = (\n",
    "    [],\n",
    "    [],\n",
    "    [],\n",
    "    [],\n",
    "    [],\n",
    "    [],\n",
    "    [],\n",
    "    [],\n",
    ")\n",
    "\n",
    "for wt_ in wts:\n",
    "    for i_CV in range(N_cv):\n",
    "        theta, p, y = get_data(wt=wt_, p0=0, seed=seed + i_CV)\n",
    "\n",
    "        logistic_model, loss = fit_data(theta, y, verbose=False)\n",
    "        logistic_model_sk, loss_SKL = fit_data_sklearn(theta, y, verbose=False)\n",
    "\n",
    "        theta0_to, wt_to, p0_to = get_params(logistic_model, verbose=False)\n",
    "        theta0_sk, wt_sk = get_params_sk(logistic_model_sk, verbose=False)\n",
    "\n",
    "        p0s_.append(p0)\n",
    "        theta0s_.append(theta0)\n",
    "        wts_.append(wt_)\n",
    "        p0_tos.append(p0_to)\n",
    "        theta0_tos.append(theta0_to)\n",
    "        theta0_sks.append(theta0_sk)\n",
    "        wt_tos.append(wt_to)\n",
    "        wt_sks.append(wt_sk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(15, 8))\n",
    "\n",
    "axs[0].scatter(wts_, p0_tos, label=\"torch\")\n",
    "axs[0].plot([min(wts_), max(wts_)], [0, 0], \"--\")\n",
    "\n",
    "axs[0].set(xlabel=\"slope (true)\", ylabel=\"p0 (predicted)\")\n",
    "axs[0].legend(loc=\"upper left\")\n",
    "\n",
    "axs[1].scatter(wts_, theta0_tos, label=\"torch\")\n",
    "axs[1].scatter(wts_, theta0_sks, label=\"sklearn\")\n",
    "axs[1].plot([min(wts_), max(wts_)], [theta0, theta0], \"--\")\n",
    "axs[1].set(xlabel=\"slope (true)\", ylabel=\"theta0 (predicted)\")\n",
    "axs[1].legend(loc=\"upper left\")\n",
    "\n",
    "axs[2].scatter(wts_, wt_tos, label=\"torch\")\n",
    "axs[2].scatter(wts_, wt_sks, label=\"sklearn\")\n",
    "axs[2].plot([min(wts_), max(wts_)], [min(wts_), max(wts_)], \"--\")\n",
    "axs[2].set(xlabel=\"slope (true)\", ylabel=\"slope (predicted)\")\n",
    "axs[2].legend(loc=\"upper left\")\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This again shows that the slope is better matched with the method presented in this notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext watermark\n",
    "%watermark -i -h -m -v -p numpy,torch,sklearn,matplotlib  -r -g -b"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "nteract": {
   "version": "0.22.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
